# main.py ‚Äî Innertrade Kai Mentor Bot
# –í–µ—Ä—Å–∏—è: 2025-09-22 (coach-struct v2)

import os
import json
import time
import logging
import threading
import hashlib
import re
from datetime import datetime, timezone
from typing import Any, Dict, Optional, List
from difflib import SequenceMatcher

import requests
from flask import Flask, request, abort, jsonify
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
import telebot
from telebot import types
from openai import OpenAI

# ========= Version =========
def get_code_version():
    try:
        with open(__file__, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()[:8]
    except Exception:
        return "unknown"

BOT_VERSION = f"2025-09-22-{get_code_version()}"

# ========= ENV =========
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "").strip()
PUBLIC_URL = os.getenv("PUBLIC_URL", "").strip()
WEBHOOK_PATH = os.getenv("WEBHOOK_PATH", "webhook").strip()
TG_SECRET = os.getenv("TG_WEBHOOK_SECRET", "").strip()
DATABASE_URL = os.getenv("DATABASE_URL", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()
OFFSCRIPT_ENABLED = os.getenv("OFFSCRIPT_ENABLED", "true").lower() == "true"
SET_WEBHOOK_FLAG = os.getenv("SET_WEBHOOK", "false").lower() == "true"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
MAX_BODY = int(os.getenv("MAX_BODY", "1000000"))
HIST_LIMIT = 12

if not TELEGRAM_TOKEN or not DATABASE_URL or not PUBLIC_URL or not TG_SECRET:
    raise RuntimeError("ENV variables missing")

# ========= Logging =========
logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
log = logging.getLogger("kai-mentor")
log.info(f"Starting bot version: {BOT_VERSION}")

# ========= Intents/Steps =========
INTENT_GREET = "greet"
INTENT_FREE = "free"
INTENT_ERR = "error"

STEP_ASK_STYLE = "ask_style"
STEP_FREE_INTRO = "free_intro"
STEP_ERR_DESCR = "err_describe"
STEP_MER_CTX = "mer_context"
STEP_MER_EMO = "mer_emotions"
STEP_MER_THO = "mer_thoughts"
STEP_MER_BEH = "mer_behavior"
STEP_GOAL = "goal_positive"
STEP_TOTE_OPS = "tote_ops"
STEP_TOTE_TEST = "tote_test"
STEP_TOTE_EXIT = "tote_exit"

MER_ORDER = [STEP_MER_CTX, STEP_MER_EMO, STEP_MER_THO, STEP_MER_BEH]

# ========= OpenAI =========
oai_client = None
openai_status = "disabled"
if OPENAI_API_KEY and OFFSCRIPT_ENABLED:
    try:
        oai_client = OpenAI(api_key=OPENAI_API_KEY)
        oai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5
        )
        openai_status = "active"
        log.info("OpenAI ready")
    except Exception as e:
        log.error(f"OpenAI init error: {e}")
        oai_client = None
        openai_status = f"error: {e}"

# ========= DB =========
engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=5,
    max_overflow=10,
    pool_timeout=30,
    pool_recycle=1800,
)

def db_exec(sql: str, params: Optional[Dict[str, Any]] = None):
    with engine.begin() as conn:
        return conn.execute(text(sql), params or {})

def init_db():
    db_exec("""
    CREATE TABLE IF NOT EXISTS user_state(
        user_id BIGINT PRIMARY KEY,
        intent TEXT,
        step TEXT,
        data TEXT,
        updated_at TIMESTAMPTZ DEFAULT now()
    );
    """)
    db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_updated_at ON user_state(updated_at)")
    db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_intent_step ON user_state(intent, step)")
    log.info("DB initialized")

# ========= State =========
def load_state(uid: int) -> Dict[str, Any]:
    row = db_exec("SELECT intent, step, data FROM user_state WHERE user_id=:uid", {"uid": uid}).mappings().first()
    if row:
        data = {}
        if row["data"]:
            try:
                data = json.loads(row["data"])
            except Exception as e:
                log.error("Failed to parse user data: %s", e)
                data = {}
        return {"user_id": uid, "intent": row["intent"] or INTENT_GREET,
                "step": row["step"] or STEP_ASK_STYLE, "data": data}
    return {"user_id": uid, "intent": INTENT_GREET, "step": STEP_ASK_STYLE, "data": {"history": []}}

def save_state(uid: int, intent=None, step=None, data=None) -> Dict[str, Any]:
    cur = load_state(uid)
    intent = intent or cur["intent"]
    step = step or cur["step"]
    new_data = cur["data"].copy()
    if data:
        new_data.update(data)
    db_exec("""
        INSERT INTO user_state (user_id, intent, step, data, updated_at)
        VALUES (:uid, :intent, :step, :data, now())
        ON CONFLICT (user_id) DO UPDATE
        SET intent=EXCLUDED.intent, step=EXCLUDED.step, data=EXCLUDED.data, updated_at=now()
    """, {"uid": uid, "intent": intent, "step": step, "data": json.dumps(new_data, ensure_ascii=False)})
    return {"user_id": uid, "intent": intent, "step": step, "data": new_data}

# ========= Bot / Flask =========
bot = telebot.TeleBot(TELEGRAM_TOKEN, parse_mode="HTML", threaded=False)
app = Flask(__name__)

MAIN_MENU = types.ReplyKeyboardMarkup(resize_keyboard=True)
MAIN_MENU.row("üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞", "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
MAIN_MENU.row("üìÑ –ü–∞—Å–ø–æ—Ä—Ç", "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏")
MAIN_MENU.row("üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ", "ü§î –ù–µ –∑–Ω–∞—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å")

STYLE_KB = types.ReplyKeyboardMarkup(resize_keyboard=True, one_time_keyboard=True)
STYLE_KB.row("—Ç—ã", "–≤—ã")

# ========= Pattern Detection & Triggers =========
RISK_PATTERNS = {
    "remove_stop": ["—É–±–∏—Ä–∞—é —Å—Ç–æ–ø", "—Å–Ω—è–ª —Å—Ç–æ–ø", "–±–µ–∑ —Å—Ç–æ–ø–∞"],
    "move_stop": ["–¥–≤–∏–≥–∞—é —Å—Ç–æ–ø", "–æ—Ç–æ–¥–≤–∏–Ω—É–ª —Å—Ç–æ–ø", "–ø–µ—Ä–µ—Å—Ç–∞–≤–∏–ª —Å—Ç–æ–ø"],
    "early_close": ["–∑–∞–∫—Ä—ã–ª —Ä–∞–Ω–æ", "–≤—ã—à–µ–ª –≤ –Ω–æ–ª—å", "–º–∏–∑–µ—Ä–Ω—ã–π –ø–ª—é—Å", "—Ä–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥"],
    "averaging": ["—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ", "–¥–æ–ª–∏–≤–∞–ª—Å—è –ø—Ä–æ—Ç–∏–≤", "–¥–æ–∫—É–ø–∞–ª –ø—Ä–æ—Ç–∏–≤"],
    "fomo": ["–ø–æ–µ–∑–¥ —É–µ–¥–µ—Ç", "—É–ø—É—Å—Ç–∏–ª", "—É–π–¥—ë—Ç –±–µ–∑ –º–µ–Ω—è", "—Å—Ç—Ä–∞—Ö —É–ø—É—Å—Ç–∏—Ç—å"],
    "rule_breaking": ["–Ω–∞—Ä—É—à–∏–ª –ø–ª–∞–Ω", "–æ—Ç–æ—à—ë–ª –æ—Ç –ø–ª–∞–Ω–∞", "–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª –ø–ª–∞–Ω"],
}

EMO_PATTERNS = {
    "self_doubt": ["—Å–æ–º–Ω–µ–≤–∞—é—Å—å", "–Ω–µ —É–≤–µ—Ä–µ–Ω", "—Å—Ç—Ä–µ—Å—Å", "–ø–∞–Ω–∏–∫–∞", "–≤–æ–ª–Ω–µ–Ω–∏–µ"],
    "fear_of_loss": ["—Å—Ç—Ä–∞—Ö –ø–æ—Ç–µ—Ä—å", "–±–æ—é—Å—å —Å—Ç–æ–ø–∞", "–Ω–µ —Ö–æ—á—É –±—ã—Ç—å –æ–±–º–∞–Ω—É—Ç—ã–º"],
    "chaos": ["—Ö–∞–æ—Å", "—Å—É–µ—Ç–∞", "–ø—É—Ç–∞—é—Å—å"],
}

def detect_trading_patterns(text: str) -> List[str]:
    tl = (text or "").lower()
    hits = []
    for name, keys in {**RISK_PATTERNS, **EMO_PATTERNS}.items():
        if any(k in tl for k in keys):
            hits.append(name)
    return hits

def should_force_structural(text: str) -> bool:
    pats = detect_trading_patterns(text)
    risk = set(pats) & set(RISK_PATTERNS.keys())
    return bool(risk) or ("fear_of_loss" in pats) or ("self_doubt" in pats)

# ========= Helpers =========
BAN_TEMPLATES = [
    "–ø–æ–Ω–∏–º–∞—é", "—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å", "–≤–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å", "–¥–∞–≤–∞–π —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º", "–±—ã–ª–æ –±—ã –ø–æ–ª–µ–∑–Ω–æ",
    "–ø–æ–ø—Ä–æ–±—É–π", "–∏—Å–ø–æ–ª—å–∑—É–π", "–ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–π—Å—è", "—É—Å—Ç–∞–Ω–æ–≤–∏", "—Å—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è", "—Å–ª–µ–¥—É–π", "–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏"
]

def strip_templates(text_in: str) -> str:
    t = text_in or ""
    for ph in BAN_TEMPLATES:
        t = re.sub(rf"(?i)\b{re.escape(ph)}[^.!?]*[.!?]", " ", t)
    t = re.sub(r'\s+', ' ', t).strip(" ,.!?")
    return t

def anti_echo(user_text: str, model_text: str) -> str:
    u = (user_text or "").strip().lower()
    m = (model_text or "").strip()
    if len(u) >= 15 and len(m) >= 15 and SequenceMatcher(None, u, m.lower()).ratio() > 0.7:
        return "–°–∫–∞–∂—É –∏–Ω–∞—á–µ: " + m
    return m

def mer_prompt_for(step: str) -> str:
    return {
        STEP_MER_CTX: "–ì–¥–µ/–∫–æ–≥–¥–∞ —ç—Ç–æ –±—ã–ª–æ? –ö–æ—Ä–æ—Ç–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        STEP_MER_EMO: "–ß—Ç–æ –ø–æ—á—É–≤—Å—Ç–≤–æ–≤–∞–ª –≤ –º–æ–º–µ–Ω—Ç–µ (2‚Äì3 —Å–ª–æ–≤–∞)?",
        STEP_MER_THO: "–ö–∞–∫–∏–µ –º—ã—Å–ª–∏ –º–µ–ª—å–∫–∞–ª–∏ (2‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã)?",
        STEP_MER_BEH: "–ß—Ç–æ —Å–¥–µ–ª–∞–ª —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏? –î–µ–π—Å—Ç–≤–∏—è.",
    }.get(step, "–ü—Ä–æ–¥–æ–ª–∂–∏–º.")

# ========= Extract summary =========
def extract_problem_summary(history: List[Dict]) -> str:
    user_msgs = [m["content"] for m in history if m.get("role") == "user"]
    pats: List[str] = []
    for m in user_msgs:
        pats.extend(detect_trading_patterns(m))
    up = sorted(set(pats))
    parts = []
    if "fomo" in up: parts.append("FOMO (—Å—Ç—Ä–∞—Ö —É–ø—É—Å—Ç–∏—Ç—å)")
    if "remove_stop" in up or "move_stop" in up: parts.append("—Ç—Ä–æ–≥–∞–µ—à—å/—Å–Ω–∏–º–∞–µ—à—å —Å—Ç–æ–ø")
    if "early_close" in up: parts.append("—Ä–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥/¬´–≤ –Ω–æ–ª—å¬ª")
    if "averaging" in up: parts.append("—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ –ø–æ–∑–∏—Ü–∏–∏")
    if "fear_of_loss" in up: parts.append("—Å—Ç—Ä–∞—Ö —Å—Ç–æ–ø–∞/–ø–æ—Ç–µ—Ä—å")
    if "self_doubt" in up: parts.append("—Å–æ–º–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ –≤—Ö–æ–¥–∞")
    return "–¢—Ä–∏–≥–≥–µ—Ä—ã: " + (", ".join(parts) if parts else "–Ω—É–∂–µ–Ω –ø—Ä–∏–º–µ—Ä")

# ========= Voice (Whisper) =========
def transcribe_voice(audio_file_path: str) -> Optional[str]:
    if not oai_client:
        log.warning("Whisper: client not available")
        return None
    try:
        log.info("Whisper: uploading %s", audio_file_path)
        with open(audio_file_path, "rb") as audio_file:
            tr = oai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"
            )
        text = getattr(tr, "text", None)
        log.info("Whisper: ok, len=%s", len(text or ""))
        return text
    except Exception as e:
        log.error("Whisper error: %s", e)
        return None

# ========= GPT (strict coach) =========
def gpt_decide(uid: int, text_in: str, st: Dict[str, Any]) -> Dict[str, Any]:
    """–°—Ç—Ä–æ–≥–∏–π –∫–æ—É—á: 1 –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –º–æ—Å—Ç–∏–∫ –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ, –±–µ–∑ —Å–æ–≤–µ—Ç–æ–≤."""
    fallback = {
        "next_step": st["step"],
        "intent": st["intent"],
        "response_text": "–í–æ–∑—å–º—ë–º —ç—Ç–æ—Ç –∫–µ–π—Å. –ß—Ç–æ –±—ã–ª–æ –ø–ª–∞–Ω–æ–º –ø–æ –≤—Ö–æ–¥—É/—Å—Ç–æ–ø—É –∏ –≤ –∫–∞–∫–æ–π –º–æ–º–µ–Ω—Ç —Ç—ã –æ—Ç –Ω–µ–≥–æ –æ—Ç—Å—Ç—É–ø–∏–ª?",
        "store": {},
        "is_structural": False
    }
    if not oai_client or not OFFSCRIPT_ENABLED:
        return fallback

    style = st["data"].get("style", "—Ç—ã")
    patterns = detect_trading_patterns(text_in)
    patterns_text = ", ".join(patterns) if patterns else "–Ω–µ—Ç"

    system_prompt = f"""
–¢—ã ‚Äî –∫–æ—É—á-–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –ø–æ —Ç—Ä–µ–π–¥–∏–Ω–≥—É –ê–ª–µ–∫—Å. –ù–µ –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—à—å, –Ω–µ –¥–∞—ë—à—å —Å–æ–≤–µ—Ç–æ–≤ –∏ —Å–ø–∏—Å–∫–æ–≤ —Ç–µ—Ö–Ω–∏–∫.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ–¥–Ω–∏–º —Ç–æ—á–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º –ø—Ä–æ–¥–≤–∏–≥–∞—Ç—å —Ä–∞–∑–±–æ—Ä, –∏ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —è–≤–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É MERCEDES ‚Üí Goal ‚Üí TOTE.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: JSON —Å –ø–æ–ª—è–º–∏:
- next_step
- intent
- response_text  (1‚Äì2 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–±–∑–∞—Ü–∞, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ –Ω–∞ ¬´{style}¬ª, –±–µ–∑ –æ–±—â–∏—Ö —Å–æ–≤–µ—Ç–æ–≤)
- store          (–æ–±—ä–µ–∫—Ç)
- is_structural  (true/false ‚Äî –µ—Å–ª–∏ –ø–æ—Ä–∞ –∏–¥—Ç–∏ –≤ MERCEDES —Å–µ–π—á–∞—Å)

–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {patterns_text}
""".strip()

    msgs = [{"role": "system", "content": system_prompt}]
    for h in st["data"].get("history", [])[-HIST_LIMIT:]:
        if h.get("role") in ("user", "assistant") and isinstance(h.get("content"), str):
            msgs.append(h)
    msgs.append({"role": "user", "content": text_in})

    try:
        res = oai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=msgs,
            temperature=0.3,
            response_format={"type": "json_object"},
        )
        raw = res.choices[0].message.content or "{}"
        dec = json.loads(raw)
        if not isinstance(dec, dict):
            return fallback
        for k in ["next_step", "intent", "response_text", "store", "is_structural"]:
            if k not in dec:
                return fallback

        # –°–∞–Ω–∏—Ç–∞–π–∑ –æ—Ç–≤–µ—Ç–∞
        resp = strip_templates(anti_echo(text_in, dec.get("response_text", "")))
        if any(b in resp.lower() for b in ["–ø–æ–ø—Ä–æ–±—É–π", "–∏—Å–ø–æ–ª—å–∑—É–π", "–ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–π—Å—è", "—É—Å—Ç–∞–Ω–æ–≤–∏", "—Å—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è", "—Å–ª–µ–¥—É–π", "–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏"]) or len(resp) < 12:
            resp = "–ù–∞ –ø—Ä–∏–º–µ—Ä–µ —ç—Ç–æ–≥–æ –∫–µ–π—Å–∞: –≥–¥–µ –∏–º–µ–Ω–Ω–æ —Ç—ã –æ—Ç—Å—Ç—É–ø–∏–ª –æ—Ç –ø–ª–∞–Ω–∞ (–≤—Ö–æ–¥/—Å—Ç–æ–ø/–≤—ã—Ö–æ–¥)?"
        dec["response_text"] = resp

        # –ï—Å–ª–∏ —Ç—Ä–∏–≥–≥–µ—Ä—ã –∂—ë—Å—Ç–∫–∏–µ ‚Äî –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if should_force_structural(text_in):
            dec["is_structural"] = True

        return dec
    except Exception as e:
        log.error("GPT decision error: %s", e)
        return fallback

# ========= Menus / Keyboards =========
def offer_structural(uid: int, st: Dict[str, Any]):
    if st["data"].get("struct_offer_shown"):
        return
    st["data"]["struct_offer_shown"] = True
    save_state(uid, data=st["data"])
    summary = extract_problem_summary(st["data"].get("history", []))
    kb = types.InlineKeyboardMarkup().row(
        types.InlineKeyboardButton("–†–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ —à–∞–≥–∞–º", callback_data="start_error_flow"),
        types.InlineKeyboardButton("–ü–æ–∫–∞ –Ω–µ—Ç", callback_data="skip_error_flow")
    )
    bot.send_message(uid, f"{summary}\n\n–ü—Ä–µ–¥–ª–∞–≥–∞—é –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä: MERCEDES ‚Üí TOTE. –ù–∞—á–∏–Ω–∞–µ–º?", reply_markup=kb)

# ========= Handlers =========
@bot.message_handler(commands=["start", "reset"])
def cmd_start(m: types.Message):
    save_state(m.from_user.id, INTENT_GREET, STEP_ASK_STYLE, {"history": []})
    bot.send_message(m.from_user.id, "üëã –ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —É–¥–æ–±–Ω–µ–µ ‚Äî <b>—Ç—ã</b> –∏–ª–∏ <b>–≤—ã</b>?", reply_markup=STYLE_KB)

@bot.message_handler(commands=["version", "v"])
def cmd_version(m: types.Message):
    info = f"üîÑ –í–µ—Ä—Å–∏—è –±–æ—Ç–∞: {BOT_VERSION}\nüìù –•—ç—à –∫–æ–¥–∞: {get_code_version()}\nüïí –í—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä–∞: {datetime.now(timezone.utc).isoformat()}\nü§ñ OpenAI: {openai_status}"
    bot.reply_to(m, info)

@bot.message_handler(commands=["menu"])
def cmd_menu(m: types.Message):
    bot.send_message(m.chat.id, "–ú–µ–Ω—é:", reply_markup=MAIN_MENU)

@bot.message_handler(content_types=['voice', 'audio'])
def handle_voice(message: types.Message):
    uid = message.from_user.id
    try:
        file_id = message.voice.file_id if message.content_type == 'voice' else message.audio.file_id
        file_info = bot.get_file(file_id)
        file_path = file_info.file_path
        log.info("Voice: file_id=%s path=%s", file_id, file_path)
        data = bot.download_file(file_path)
        tmp_name = f"voice_{uid}_{int(time.time())}.ogg"
        with open(tmp_name, "wb") as f:
            f.write(data)
        txt = transcribe_voice(tmp_name)
        try:
            os.remove(tmp_name)
        except Exception:
            pass
        if not txt:
            bot.reply_to(message, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –°–∫–∞–∂–∏ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç–æ–º.")
            return
        handle_text_message(uid, txt, original_message=message)
    except Exception as e:
        log.error("Voice processing error: %s", e)
        bot.reply_to(message, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–∞. –ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç–æ–º, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")

@bot.message_handler(content_types=["text"])
def on_text(m: types.Message):
    handle_text_message(m.from_user.id, m.text.strip(), m)

def handle_text_message(uid: int, text_in: str, original_message=None):
    st = load_state(uid)
    log.info("User %s: intent=%s step=%s text='%s'", uid, st["intent"], st["step"], text_in[:200])

    # history (user)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": text_in})
    st["data"]["history"] = history

    # Greeting: –≤—ã–±–æ—Ä —Å—Ç–∏–ª—è
    if st["intent"] == INTENT_GREET and st["step"] == STEP_ASK_STYLE:
        if text_in.lower() in ("—Ç—ã", "–≤—ã"):
            st["data"]["style"] = text_in.lower()
            save_state(uid, INTENT_FREE, STEP_FREE_INTRO, st["data"])
            bot.send_message(uid, f"–ü—Ä–∏–Ω—è—Ç–æ ({text_in}). –ß—Ç–æ —Å–µ–π—á–∞—Å –≤ —Ç—Ä–µ–π–¥–∏–Ω–≥–µ —Ö–æ—á–µ—à—å –ø–æ–ø—Ä–∞–≤–∏—Ç—å?", reply_markup=MAIN_MENU)
        else:
            save_state(uid, data=st["data"])
            bot.send_message(uid, "–í—ã–±–µ—Ä–∏ ¬´—Ç—ã¬ª –∏–ª–∏ ¬´–≤—ã¬ª.", reply_markup=STYLE_KB)
        return

    # Structural flow
    if st["intent"] == INTENT_ERR:
        handle_structural(uid, text_in, st)
        return

    # Free flow (coach)
    decision = gpt_decide(uid, text_in, st)
    resp = decision.get("response_text") or "–ù–∞ —ç—Ç–æ–º –∫–µ–π—Å–µ: –≥–¥–µ –∏–º–µ–Ω–Ω–æ —Ç—ã –æ—Ç—Å—Ç—É–ø–∏–ª –æ—Ç –ø–ª–∞–Ω–∞ (–≤—Ö–æ–¥/—Å—Ç–æ–ø/–≤—ã—Ö–æ–¥)?"

    # history (assistant)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "assistant", "content": resp})

    merged = st["data"].copy()
    store = decision.get("store", {})
    if isinstance(store, dict):
        merged.update(store)
    merged["history"] = history

    new_intent = decision.get("intent") or st["intent"]
    new_step = decision.get("next_step") or st["step"]
    st_after = save_state(uid, new_intent, new_step, merged)

    if original_message:
        bot.reply_to(original_message, resp, reply_markup=MAIN_MENU)
    else:
        bot.send_message(uid, resp, reply_markup=MAIN_MENU)

    # –ê–≤—Ç–æ–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã ‚Äî –µ—Å–ª–∏ GPT —Å–∫–∞–∑–∞–ª is_structural –∏–ª–∏ —è–≤–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã
    if decision.get("is_structural", False) or should_force_structural(text_in):
        offer_structural(uid, st_after)

# ========= Structural Flow =========
def handle_structural(uid: int, text_in: str, st: Dict[str, Any]):
    # a) –æ–ø–∏—Å–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
    if st["step"] == STEP_ERR_DESCR:
        new_data = st["data"].copy()
        new_data["error_description"] = text_in
        save_state(uid, INTENT_ERR, STEP_MER_CTX, new_data)
        bot.send_message(uid, mer_prompt_for(STEP_MER_CTX))
        return

    # b) MERCEDES
    if st["step"] in MER_ORDER:
        mer = st["data"].get("mer", {})
        mer[st["step"]] = text_in
        new_data = st["data"].copy()
        new_data["mer"] = mer

        idx = MER_ORDER.index(st["step"])
        if idx + 1 < len(MER_ORDER):
            nxt = MER_ORDER[idx + 1]
            save_state(uid, INTENT_ERR, nxt, new_data)
            bot.send_message(uid, mer_prompt_for(nxt))
        else:
            save_state(uid, INTENT_ERR, STEP_GOAL, new_data)
            bot.send_message(uid, "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é —Ü–µ–ª—å: —á—Ç–æ –¥–µ–ª–∞–µ—à—å –≤–º–µ—Å—Ç–æ –ø—Ä–µ–∂–Ω–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è?")
        return

    # c) Goal
    if st["step"] == STEP_GOAL:
        new_data = st["data"].copy()
        new_data["goal"] = text_in
        save_state(uid, INTENT_ERR, STEP_TOTE_OPS, new_data)
        bot.send_message(uid, "–ù–∞–∑–æ–≤–∏ 2‚Äì3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —à–∞–≥–∞ –¥–ª—è –±–ª–∏–∂–∞–π—à–∏—Ö 3 —Å–¥–µ–ª–æ–∫ (–∫–æ—Ä–æ—Ç–∫–æ, —Å–ø–∏—Å–∫–æ–º).")
        return

    # d) TOTE - ops
    if st["step"] == STEP_TOTE_OPS:
        tote = st["data"].get("tote", {})
        tote["ops"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, INTENT_ERR, STEP_TOTE_TEST, new_data)
        bot.send_message(uid, "–ö–∞–∫ –ø–æ–π–º—ë—à—å, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å? –û–¥–∏–Ω –ø—Ä–æ—Å—Ç–æ–π –∫—Ä–∏—Ç–µ—Ä–∏–π.")
        return

    # e) TOTE - test
    if st["step"] == STEP_TOTE_TEST:
        tote = st["data"].get("tote", {})
        tote["test"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, INTENT_ERR, STEP_TOTE_EXIT, new_data)
        bot.send_message(uid, "–ß—Ç–æ —Å–¥–µ–ª–∞–µ—à—å, –µ—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫–∞–∂–µ—Ç ¬´–Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å¬ª?")
        return

    # f) TOTE - exit
    if st["step"] == STEP_TOTE_EXIT:
        tote = st["data"].get("tote", {})
        tote["exit"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote

        mer = new_data.get('mer', {})
        summary = [
            "<b>–ò—Ç–æ–≥ —Ä–∞–∑–±–æ—Ä–∞</b>",
            f"–û—à–∏–±–∫–∞: {new_data.get('error_description', '‚Äî')}",
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {mer.get(STEP_MER_CTX, '‚Äî')}",
            f"–≠–º–æ—Ü–∏–∏: {mer.get(STEP_MER_EMO, '‚Äî')}",
            f"–ú—ã—Å–ª–∏: {mer.get(STEP_MER_THO, '‚Äî')}",
            f"–ü–æ–≤–µ–¥–µ–Ω–∏–µ: {mer.get(STEP_MER_BEH, '‚Äî')}",
            f"–¶–µ–ª—å: {new_data.get('goal', '‚Äî')}",
            f"–®–∞–≥–∏: {new_data.get('tote', {}).get('ops', '‚Äî')}",
            f"–ü—Ä–æ–≤–µ—Ä–∫–∞: {new_data.get('tote', {}).get('test', '‚Äî')}",
            f"–ï—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ: {new_data.get('tote', {}).get('exit', '‚Äî')}",
        ]
        save_state(uid, INTENT_FREE, STEP_FREE_INTRO, new_data)
        bot.send_message(uid, "\n".join(summary), reply_markup=MAIN_MENU)
        bot.send_message(uid, "–î–æ–±–∞–≤–∏–º —ç—Ç–æ –≤ —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏ –∏–ª–∏ –∏–¥—ë–º –¥–∞–ª—å—à–µ?")

# ========= Menu handlers =========
MENU_BTNS = {
    "üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞": "error",
    "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é": "strategy",
    "üìÑ –ü–∞—Å–ø–æ—Ä—Ç": "passport",
    "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏": "weekpanel",
    "üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ": "panic",
    "ü§î –ù–µ –∑–Ω–∞—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å": "start_help",
}

@bot.message_handler(func=lambda m: m.text in MENU_BTNS.keys())
def handle_menu(m: types.Message):
    uid = m.from_user.id
    st = load_state(uid)
    label = m.text
    code = MENU_BTNS[label]

    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": label})
    st["data"]["history"] = history

    if code == "error":
        save_state(uid, INTENT_ERR, STEP_ERR_DESCR, st["data"])
        bot.send_message(uid, "–û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–µ–π—Å –æ—à–∏–±–∫–∏: –≥–¥–µ/–∫–æ–≥–¥–∞, –≤—Ö–æ–¥/—Å—Ç–æ–ø/–ø–ª–∞–Ω, –≥–¥–µ –æ—Ç—Å—Ç—É–ø–∏–ª, —á–µ–º –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å.")
    elif code == "start_help":
        bot.send_message(uid, "–ü–ª–∞–Ω: 1) –±—ã—Å—Ç—Ä—ã–π —Ä–∞–∑–±–æ—Ä –æ—à–∏–±–∫–∏, 2) —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏, 3) —Å–∫–µ–ª–µ—Ç –¢–°. –° —á–µ–≥–æ –Ω–∞—á–Ω—ë–º?", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])
    else:
        bot.send_message(uid, "–û–∫. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —É—Å–∫–æ—Ä–∏—Ç—å—Å—è ‚Äî –Ω–∞–∂–º–∏ ¬´üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞¬ª.", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])

# ========= Callbacks =========
@bot.callback_query_handler(func=lambda call: True)
def on_callback(call: types.CallbackQuery):
    uid = call.from_user.id
    data = call.data or ""
    bot.answer_callback_query(call.id, "–û–∫")
    if data == "start_error_flow":
        st = load_state(uid)
        st["data"]["problem_confirmed"] = True
        save_state(uid, INTENT_ERR, STEP_ERR_DESCR, st["data"])
        bot.send_message(uid, "–ù–∞—á–∏–Ω–∞–µ–º —Ä–∞–∑–±–æ—Ä. –û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π: –≤—Ö–æ–¥/–ø–ª–∞–Ω, –≥–¥–µ –æ—Ç—Å—Ç—É–ø–∏–ª, —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")
    elif data == "skip_error_flow":
        bot.send_message(uid, "–•–æ—Ä–æ—à–æ. –í–µ—Ä–Ω—ë–º—Å—è –∫ —ç—Ç–æ–º—É, –∫–æ–≥–¥–∞ –±—É–¥–µ—à—å –≥–æ—Ç–æ–≤.", reply_markup=MAIN_MENU)

# ========= HTTP =========
def _now_iso():
    return datetime.now(timezone.utc).isoformat()

@app.get("/")
def root():
    return jsonify({"ok": True, "time": _now_iso()})

@app.get("/version")
def version_api():
    return jsonify({"version": BOT_VERSION, "code_hash": get_code_version(), "status": "running", "timestamp": _now_iso()})

@app.post(f"/{WEBHOOK_PATH}")
def webhook():
    if request.headers.get("X-Telegram-Bot-Api-Secret-Token") != TG_SECRET:
        abort(401)
    if request.content_length and request.content_length > MAX_BODY:
        abort(413, description="Body too large")
    body = request.get_data()
    if not body:
        abort(400, description="Empty body")
    try:
        update = telebot.types.Update.de_json(body.decode("utf-8"))
        if update is None:
            log.error("Failed to parse update")
            abort(400, description="Invalid update")
        bot.process_new_updates([update])
        return "OK", 200
    except Exception as e:
        log.error("Webhook processing error: %s", e)
        abort(500)

# ========= Maintenance =========
def cleanup_old_states(days: int = 30):
    try:
        db_exec("DELETE FROM user_state WHERE updated_at < NOW() - make_interval(days => :days)", {"days": days})
        log.info("Old user states cleanup done (> %s days).", days)
    except Exception as e:
        log.error("Cleanup error: %s", e)

def cleanup_scheduler():
    while True:
        time.sleep(24 * 60 * 60)
        cleanup_old_states(30)

# ========= Init on import (for gunicorn) =========
try:
    init_db()
    log.info("DB initialized (import)")
except Exception as e:
    log.error("DB init (import) failed: %s", e)

if SET_WEBHOOK_FLAG:
    try:
        bot.remove_webhook()
        time.sleep(1)
        bot.set_webhook(
            url=f"{PUBLIC_URL}/{WEBHOOK_PATH}",
            secret_token=TG_SECRET,
            allowed_updates=["message", "callback_query"]
        )
        log.info("Webhook set to %s/%s", PUBLIC_URL, WEBHOOK_PATH)
    except Exception as e:
        log.error("Webhook setup error: %s", e)

try:
    th = threading.Thread(target=cleanup_scheduler, daemon=True)
    th.start()
except Exception as e:
    log.error("Can't start cleanup thread: %s", e)

# ========= Dev run =========
if __name__ == "__main__":
    port = int(os.getenv("PORT", "10000"))
    app.run(host="0.0.0.0", port=port)
