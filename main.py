# main.py ‚Äî Innertrade Kai Mentor Bot
# –í–µ—Ä—Å–∏—è: 2025-09-22-v5

import os
import json
import time
import logging
import threading
import hashlib
import re
from datetime import datetime, timezone
from typing import Any, Dict, Optional, List
from difflib import SequenceMatcher

import requests
from flask import Flask, request, abort, jsonify
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
import telebot
from telebot import types
from openai import OpenAI

# ========= Version Check =========
def get_code_version():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ö—ç—à —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –∫–æ–¥–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    try:
        with open(__file__, 'rb') as f:
            content = f.read()
            return hashlib.md5(content).hexdigest()[:8]
    except Exception:
        return "unknown"

BOT_VERSION = f"2025-09-22-{get_code_version()}"

# ========= ENV =========
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "").strip()
PUBLIC_URL = os.getenv("PUBLIC_URL", "").strip()
WEBHOOK_PATH = os.getenv("WEBHOOK_PATH", "webhook").strip()
TG_SECRET = os.getenv("TG_WEBHOOK_SECRET", "").strip()
DATABASE_URL = os.getenv("DATABASE_URL", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()
OFFSCRIPT_ENABLED = os.getenv("OFFSCRIPT_ENABLED", "true").lower() == "true"
SET_WEBHOOK_FLAG = os.getenv("SET_WEBHOOK", "false").lower() == "true"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
MAX_BODY = int(os.getenv("MAX_BODY", "1000000"))
HIST_LIMIT = 12

# Validation
if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN is required")
if not DATABASE_URL:
    raise RuntimeError("DATABASE_URL is required")
if not PUBLIC_URL:
    raise RuntimeError("PUBLIC_URL is required")
if not WEBHOOK_PATH:
    raise RuntimeError("WEBHOOK_PATH is required")
if not TG_SECRET:
    raise RuntimeError("TG_WEBHOOK_SECRET is required")

# Logging
logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
log = logging.getLogger("innertrade")
log.info(f"Starting bot version: {BOT_VERSION}")

# ========= INTENTS/STEPS =========
INTENT_GREET = "greet"
INTENT_FREE = "free"
INTENT_ERR = "error"

STEP_ASK_STYLE = "ask_style"
STEP_FREE_INTRO = "free_intro"
STEP_ERR_DESCR = "err_describe"
STEP_MER_CTX = "mer_context"
STEP_MER_EMO = "mer_emotions"
STEP_MER_THO = "mer_thoughts"
STEP_MER_BEH = "mer_behavior"
STEP_GOAL = "goal_positive"
STEP_TOTE_OPS = "tote_ops"
STEP_TOTE_TEST = "tote_test"
STEP_TOTE_EXIT = "tote_exit"
STEP_DONE = "done"

MER_ORDER = [STEP_MER_CTX, STEP_MER_EMO, STEP_MER_THO, STEP_MER_BEH]

# ========= OpenAI =========
oai_client = None
openai_status = "disabled"

if OPENAI_API_KEY and OFFSCRIPT_ENABLED:
    try:
        oai_client = OpenAI(api_key=OPENAI_API_KEY)
        # –ª—ë–≥–∫–∏–π —Ç–µ—Å—Ç
        oai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5
        )
        openai_status = "active"
        log.info("OpenAI client initialized successfully")
    except Exception as e:
        log.error(f"OpenAI init error: {e}")
        oai_client = None
        openai_status = f"error: {str(e)}"
else:
    log.warning("OpenAI disabled ‚Äî missing API key or OFFSCRIPT_ENABLED=false")
    openai_status = "disabled"

# ========= DB =========
engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=5,
    max_overflow=10,
    pool_timeout=30,
    pool_recycle=1800,
)

def db_exec(sql: str, params: Optional[Dict[str, Any]] = None):
    try:
        with engine.begin() as conn:
            return conn.execute(text(sql), params or {})
    except Exception as e:
        log.error("DB error: %s | SQL: %s | params: %s", e, sql, params)
        raise

def init_db(silent: bool = False):
    try:
        db_exec("""
        CREATE TABLE IF NOT EXISTS user_state(
            user_id BIGINT PRIMARY KEY,
            intent TEXT,
            step TEXT,
            data TEXT,
            updated_at TIMESTAMPTZ DEFAULT now()
        );
        """)
        db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_updated_at ON user_state(updated_at)")
        db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_intent_step ON user_state(intent, step)")
        if not silent:
            log.info("DB initialized")
    except Exception as e:
        # –Ω–µ –ø–∞–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å–æ–º ‚Äî –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º, —á—Ç–æ–±—ã health –æ—Å—Ç–∞–≤–∞–ª—Å—è 200
        log.error("init_db error (soft): %s", e)

# ========= State Management =========
def load_state(uid: int) -> Dict[str, Any]:
    try:
        row = db_exec(
            "SELECT intent, step, data FROM user_state WHERE user_id = :uid",
            {"uid": uid}
        ).mappings().first()
        if row:
            data = {}
            if row["data"]:
                try:
                    data = json.loads(row["data"])
                except Exception as e:
                    log.error("Failed to parse user data: %s", e)
                    data = {}
            return {
                "user_id": uid,
                "intent": row["intent"] or INTENT_GREET,
                "step": row["step"] or STEP_ASK_STYLE,
                "data": data
            }
    except Exception as e:
        log.error("load_state error: %s", e)

    return {"user_id": uid, "intent": INTENT_GREET, "step": STEP_ASK_STYLE, "data": {"history": []}}

def save_state(uid: int, intent: Optional[str] = None,
               step: Optional[str] = None, data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    cur = load_state(uid)
    new_intent = intent if intent is not None else cur["intent"]
    new_step = step if step is not None else cur["step"]
    new_data = cur["data"].copy()
    if data:
        new_data.update(data)

    payload = {
        "uid": uid,
        "intent": new_intent,
        "step": new_step,
        "data": json.dumps(new_data, ensure_ascii=False),
    }
    db_exec("""
        INSERT INTO user_state (user_id, intent, step, data, updated_at)
        VALUES (:uid, :intent, :step, :data, now())
        ON CONFLICT (user_id) DO UPDATE
        SET intent = EXCLUDED.intent,
            step   = EXCLUDED.step,
            data   = EXCLUDED.data,
            updated_at = now();
    """, payload)

    return {"user_id": uid, "intent": new_intent, "step": new_step, "data": new_data}

# ========= Bot & Flask =========
bot = telebot.TeleBot(TELEGRAM_TOKEN, parse_mode="HTML", threaded=False)
app = Flask(__name__)

# ========= Keyboards =========
def main_menu() -> types.ReplyKeyboardMarkup:
    kb = types.ReplyKeyboardMarkup(resize_keyboard=True)
    kb.row("üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞", "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
    kb.row("üìÑ –ü–∞—Å–ø–æ—Ä—Ç", "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏")
    kb.row("üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ", "ü§î –ù–µ –∑–Ω–∞—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å")
    return kb

MAIN_MENU = main_menu()

def style_kb() -> types.ReplyKeyboardMarkup:
    kb = types.ReplyKeyboardMarkup(resize_keyboard=True, one_time_keyboard=True)
    kb.row("—Ç—ã", "–≤—ã")
    return kb

# ========= Pattern Detection =========
def detect_trading_patterns(text: str) -> List[str]:
    """–î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª"""
    patterns = {
        "remove_stop": ["—É–±–∏—Ä–∞—é —Å—Ç–æ–ø", "—É–±—Ä–∞–ª —Å—Ç–æ–ø", "—É–±—Ä–∞–ª–∞ —Å—Ç–æ–ø", "—É–±–∏—Ä–∞—é —Å—Ç–æ–ø-–ª–æ—Å—Å", "—Å–Ω–∏–º–∞—é —Å—Ç–æ–ø"],
        "move_stop": ["–¥–≤–∏–≥–∞—é —Å—Ç–æ–ø", "–ø–µ—Ä–µ—Å—Ç–∞–≤–ª—è—é —Å—Ç–æ–ø", "–ø–µ—Ä–µ–¥–≤–∏–≥–∞—é —Å—Ç–æ–ø", "–æ—Ç–æ–¥–≤–∏–≥–∞–ª —Å—Ç–æ–ø", "–ø–µ—Ä–µ–Ω—ë—Å —Å—Ç–æ–ø"],
        "early_close": ["—Ä–∞–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–∫—Ä—ã–ª", "–∑–∞–∫—Ä—ã–ª —Ä–∞–Ω–æ", "–≤—ã—Ö–æ–¥ —Ä–∞–Ω—å—à–µ", "–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–ª —Ä–∞–Ω–æ", "–º–∞–ª–µ–Ω—å–∫–∏–π –ø–ª—é—Å –∑–∞–∫—Ä—ã–ª"],
        "averaging": ["—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ", "—É—Å—Ä–µ–¥–Ω—è–ª", "–¥–æ–±–∞–≤–ª—è–ª—Å—è", "–¥–æ–∫—É–ø–∞–ª –ø—Ä–æ—Ç–∏–≤", "–¥–æ–ª–∏–≤–∞–ª—Å—è"],
        "break_even": ["–≤ –±–µ–∑—É–±—ã—Ç–æ–∫", "–ø–µ—Ä–µ–≤—ë–ª –≤ –Ω–æ–ª—å", "–ø–µ—Ä–µ–≤–æ–¥ –≤ –±–µ–∑—É–±—ã—Ç–æ–∫"],
        "small_profit": ["–º–µ–ª–∫–∏–π –ø—Ä–æ—Ñ–∏—Ç", "–º–∏–∑–µ—Ä–Ω—ã–π –ø–ª—é—Å", "—Å–∫–æ—Ä–æ —Ñ–∏–∫—Å–∏—Ä—É—é"],
        "self_doubt": ["–Ω–µ —É–≤–µ—Ä–µ–Ω", "—Å–æ–º–Ω–µ–≤–∞—é—Å—å", "–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", "—Å—Ç—Ä–µ—Å—Å—É—é", "–≤–æ–ª–Ω–µ–Ω–∏–µ", "–ø–∞–Ω–∏–∫–∞"],
        "fear_of_loss": ["—Å—Ç—Ä–∞—Ö –ø–æ—Ç–µ—Ä—è—Ç—å", "–±–æ—é—Å—å –ø–æ—Ç–µ—Ä—è—Ç—å", "–±–æ—é—Å—å —É–±—ã—Ç–∫–∞"],
        "chaos": ["—Ö–∞–æ—Å", "—Ç–æ–ø—á—É—Å—å", "–Ω–µ –∑–Ω–∞—é —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å", "–±–æ–∫–æ–≤–∏–∫ —Å–º—É—â–∞–ª"],
        "rule_breaking": ["–Ω–∞—Ä—É—à–∞—é –ø—Ä–∞–≤–∏–ª–∞", "–∏–≥–Ω–æ—Ä–∏—Ä—É—é –ø—Ä–∞–≤–∏–ª–∞", "–æ—Ç–æ—à—ë–ª –æ—Ç –ø–ª–∞–Ω–∞"]
    }
    detected = []
    tl = (text or "").lower()
    for name, keys in patterns.items():
        if any(k in tl for k in keys):
            detected.append(name)
    return detected

def should_suggest_deep_analysis(text: str, patterns: List[str]) -> bool:
    crisis_words = ["—Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏", "–¥–∞–≤–Ω–æ", "–Ω–µ –º–æ–≥—É", "–Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è", "–ø–æ—Å—Ç–æ—è–Ω–Ω–æ", "—Ä–µ–≥—É–ª—è—Ä–Ω–æ", "–∫–∞–∂–¥—ã–π —Ä–∞–∑"]
    has_crisis = any(w in (text or "").lower() for w in crisis_words)
    return has_crisis or len(patterns) >= 2 or any(p in patterns for p in ["remove_stop", "move_stop", "averaging", "early_close"])

# ========= Helpers =========
def anti_echo(user_text: str, model_text: str) -> str:
    u = (user_text or "").strip().lower()
    m = (model_text or "").strip()
    if len(u) < 15 or len(m) < 15:
        return m
    similarity = SequenceMatcher(None, u, m.lower()).ratio()
    if similarity > 0.7:
        return "–°–∫–∞–∂—É –ø–æ-—Å–≤–æ–µ–º—É: " + m
    return m

TEMPLATE_CHUNKS = [
    "–ø–æ–Ω–∏–º–∞—é", "—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å", "–≤–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å", "—Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å", "–¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä",
    "—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞", "–º–æ–∂–µ—à—å —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å", "–∫–∞–∫ —Ç—ã –æ–±—ã—á–Ω–æ",
    "—á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç", "–∫–∞–∫–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ", "–∫–∞–∫ –¥–æ–ª–≥–æ", "–≤ –∫–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö",
    "—ç—Ç–æ –ø–æ–º–æ–∂–µ—Ç", "–¥–∞–≤–∞–π —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º", "–±—ã–ª–æ –±—ã –ø–æ–ª–µ–∑–Ω–æ", "–ø–æ—Å—Ç–∞—Ä–∞–µ–º—Å—è"
]

def remove_template_phrases(text_in: str) -> str:
    text = text_in or ""
    # –≤—ã—Ä–µ–∂–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è –Ω–∞ ¬´—à–∞–±–ª–æ–Ω¬ª
    for ph in TEMPLATE_CHUNKS:
        text = re.sub(rf"(?i)\b{re.escape(ph)}[^.!?]*[.!?]", " ", text)
    text = re.sub(r'\s+', ' ', text).strip(" ,.!?")
    return text

def mer_prompt_for(step: str) -> str:
    prompts = {
        STEP_MER_CTX: "–í –∫–∞–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ —ç—Ç–æ –æ–±—ã—á–Ω–æ —Å–ª—É—á–∞–µ—Ç—Å—è? –û–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        STEP_MER_EMO: "–ß—Ç–æ —á—É–≤—Å—Ç–≤—É–µ—à—å –≤ –º–æ–º–µ–Ω—Ç –æ—à–∏–±–∫–∏ (2‚Äì3 —Å–ª–æ–≤–∞)?",
        STEP_MER_THO: "–ö–∞–∫–∏–µ —Ñ—Ä–∞–∑—ã –∫—Ä—É—Ç—è—Ç—Å—è –≤ –≥–æ–ª–æ–≤–µ (2‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏–µ)?",
        STEP_MER_BEH: "–ß—Ç–æ –¥–µ–ª–∞–µ—à—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏? –û–ø–∏—à–∏ –¥–µ–π—Å—Ç–≤–∏—è.",
    }
    return prompts.get(step, "–ü—Ä–æ–¥–æ–ª–∂–∏–º.")

def extract_problem_summary(history: List[Dict]) -> str:
    user_messages = [msg["content"] for msg in history if msg.get("role") == "user"]
    pats: List[str] = []
    for msg in user_messages:
        pats.extend(detect_trading_patterns(msg))
    up = sorted(set(pats))
    parts = []
    if "self_doubt" in up: parts.append("–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –≤—Ö–æ–¥–∞")
    if "fear_of_loss" in up: parts.append("—Å—Ç—Ä–∞—Ö –ø–æ—Ç–µ—Ä—å")
    if "remove_stop" in up or "move_stop" in up: parts.append("—Ç—Ä–æ–≥–∞–Ω–∏–µ/—Å–Ω—è—Ç–∏–µ —Å—Ç–æ–ø–∞")
    if "early_close" in up: parts.append("—Ä–∞–Ω–Ω–µ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ")
    if "averaging" in up: parts.append("—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ –ø–æ–∑–∏—Ü–∏–∏")
    if "chaos" in up: parts.append("—Ö–∞–æ—Å –∏ —Å–æ–º–Ω–µ–Ω–∏—è")
    if "rule_breaking" in up: parts.append("–Ω–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –¢–°")
    return "–û—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã: " + (", ".join(parts) if parts else "–Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–∏—Ç—å –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ")

# ========= Voice Handling =========
def transcribe_voice(audio_file_path: str) -> Optional[str]:
    if not oai_client:
        return None
    try:
        with open(audio_file_path, "rb") as audio_file:
            transcript = oai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"
            )
            return transcript.text
    except Exception as e:
        log.error("Voice transcription error: %s", e)
        return None

# ========= GPT Decision Maker =========
def gpt_decide(uid: int, text_in: str, st: Dict[str, Any]) -> Dict[str, Any]:
    fallback = {
        "next_step": st["step"],
        "intent": st["intent"],
        "response_text": "–û–∫–µ–π. –î–∞–≤–∞–π –≤–æ–∑—å–º—ë–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏ —Ä–∞–∑–±–µ—Ä—ë–º –ø–æ —à–∞–≥–∞–º?",
        "store": {},
        "is_structural": False
    }
    if not oai_client or not OFFSCRIPT_ENABLED:
        log.warning(f"OpenAI not available: oai_client={oai_client}, OFFSCRIPT_ENABLED={OFFSCRIPT_ENABLED}")
        return fallback

    try:
        history = st["data"].get("history", [])
        style = st["data"].get("style", "—Ç—ã")
        patterns = detect_trading_patterns(text_in)
        patterns_text = ", ".join(patterns) if patterns else "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"

        system_prompt = f"""
–¢—ã ‚Äî –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –ø–æ —Ç—Ä–µ–π–¥–∏–Ω–≥—É –ê–ª–µ–∫—Å. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (1‚Äì2 –∞–±–∑–∞—Ü–∞) –∏ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ.
–û–±—Ä–∞—â–∞–π—Å—è –Ω–∞ ¬´{style}¬ª. –ò–∑–±–µ–≥–∞–π —à–∞–±–ª–æ–Ω–æ–≤ –∏ –≤–æ–¥—ã (–Ω–∏–∫–∞–∫–∏—Ö ¬´–ø–æ–Ω–∏–º–∞—é/—ç—Ç–æ –ø–æ–º–æ–∂–µ—Ç/–¥–∞–≤–∞–π —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º¬ª).
–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —à–∞–≥.

–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {patterns_text}

–û—Ç–≤–µ—Ç –≤—Å–µ–≥–¥–∞ –≤ JSON:
  next_step: —Å—Ç—Ä–æ–∫–∞,
  intent: —Å—Ç—Ä–æ–∫–∞,
  response_text: —Å—Ç—Ä–æ–∫–∞,
  store: –æ–±—ä–µ–∫—Ç,
  is_structural: true/false.

–ü—Ä–∞–≤–∏–ª–∞:
- –ù–µ –∑–∞–¥–∞–≤–∞–π –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ ¬´–∫–∞–∫ –¥–æ–ª–≥–æ¬ª, ¬´–≤ –∫–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö¬ª.
- –û—Ç–≤–µ—á–∞–π –ø–æ –¥–µ–ª—É. –ï—Å–ª–∏ –≤–∏–¥–∏—à—å, —á—Ç–æ –Ω—É–∂–µ–Ω —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π —Ä–∞–∑–±–æ—Ä, –ø–æ–º–µ—Ç—å is_structural=true –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–µ—Ä–µ–π—Ç–∏ –∫ —à–∞–≥–∞–º.
        """.strip()

        msgs = [{"role": "system", "content": system_prompt}]
        for h in history[-HIST_LIMIT:]:
            if h.get("role") in ("user", "assistant") and isinstance(h.get("content"), str):
                msgs.append({"role": h["role"], "content": h["content"]})
        msgs.append({"role": "user", "content": text_in})

        res = oai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=msgs,
            temperature=0.4,
            response_format={"type": "json_object"},
        )
        raw = res.choices[0].message.content or "{}"
        dec = json.loads(raw)

        for k in ["next_step", "intent", "response_text", "store", "is_structural"]:
            if k not in dec:
                return fallback
        if not isinstance(dec.get("store"), dict):
            dec["store"] = {}
        if not isinstance(dec.get("is_structural"), bool):
            dec["is_structural"] = False

        dec["response_text"] = remove_template_phrases(anti_echo(text_in, dec["response_text"]))

        # –µ—Å–ª–∏ –≤—Å—ë –µ—â—ë –ø—É—Å—Ç–æ–≤–∞—Ç–æ ‚Äî —É—Å–∏–ª–∏–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É
        if len(dec["response_text"]) < 20 or any(x in dec["response_text"].lower() for x in ["–ø–æ–º–æ–∂–µ—Ç", "—Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º", "–ø–æ–ª–µ–∑–Ω–æ"]):
            res2 = oai_client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=msgs,
                temperature=0.7,
                response_format={"type": "json_object"},
            )
            raw2 = res2.choices[0].message.content or "{}"
            dec2 = json.loads(raw2)
            if isinstance(dec2, dict) and dec2.get("response_text"):
                dec["response_text"] = remove_template_phrases(anti_echo(text_in, dec2["response_text"]))

        return dec

    except Exception as e:
        log.error("GPT decision error: %s", e)
        return fallback

# ========= Commands =========
@bot.message_handler(commands=["ping"])
def cmd_ping(m: types.Message):
    bot.reply_to(m, "pong")

@bot.message_handler(commands=["menu"])
def cmd_menu(m: types.Message):
    bot.send_message(m.chat.id, "–ú–µ–Ω—é:", reply_markup=MAIN_MENU)

@bot.message_handler(commands=["help"])
def cmd_help(m: types.Message):
    bot.reply_to(m, "–Ø –ø–æ–º–æ–≥—É —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ—à–∏–±–∫–∏ (MERCEDES ‚Üí TOTE), –ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏ –∏ —Å–æ–±—Ä–∞—Ç—å —Å–∫–µ–ª–µ—Ç –¢–°. –ù–∞—á–Ω–∏ —Å –∫–Ω–æ–ø–∫–∏ ¬´üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞¬ª –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏ —Å–∏—Ç—É–∞—Ü–∏—é.", reply_markup=MAIN_MENU)

@bot.message_handler(commands=["version", "v"])
def cmd_version(m: types.Message):
    version_info = f"""üîÑ –í–µ—Ä—Å–∏—è –±–æ—Ç–∞: {BOT_VERSION}
üìù –•—ç—à –∫–æ–¥–∞: {get_code_version()}
üïí –í—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä–∞: {datetime.now(timezone.utc).isoformat()}
ü§ñ OpenAI: {openai_status}"""
    bot.reply_to(m, version_info)

@bot.message_handler(commands=["debug"])
def cmd_debug(m: types.Message):
    debug_info = {
        "openai_available": bool(oai_client),
        "offscript_enabled": OFFSCRIPT_ENABLED,
        "has_api_key": bool(OPENAI_API_KEY),
        "model": OPENAI_MODEL,
        "openai_status": openai_status
    }
    bot.reply_to(m, f"<code>{json.dumps(debug_info, ensure_ascii=False, indent=2)}</code>")

@bot.message_handler(commands=["status"])
def cmd_status(m: types.Message):
    uid = m.from_user.id
    st = load_state(uid)
    response = {
        "ok": True,
        "time": datetime.now(timezone.utc).isoformat(),
        "intent": st["intent"],
        "step": st["step"],
        "db": "ok"
    }
    bot.reply_to(m, f"<code>{json.dumps(response, ensure_ascii=False, indent=2)}</code>")

@bot.message_handler(commands=["reset", "start"])
def cmd_reset(m: types.Message):
    uid = m.from_user.id
    save_state(uid, intent=INTENT_GREET, step=STEP_ASK_STYLE, data={"history": []})
    bot.send_message(
        uid,
        f"üëã –ü—Ä–∏–≤–µ—Ç, {m.from_user.first_name or '—Ç—Ä–µ–π–¥–µ—Ä'}!\n–ö–∞–∫ —É–¥–æ–±–Ω–µ–µ –æ–±—Ä–∞—â–∞—Ç—å—Å—è ‚Äî <b>—Ç—ã</b> –∏–ª–∏ <b>–≤—ã</b>? (–Ω–∞–ø–∏—à–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ)",
        reply_markup=style_kb()
    )

# ========= Media Handler =========
@bot.message_handler(content_types=['voice', 'audio'])
def handle_voice(message: types.Message):
    try:
        uid = message.from_user.id
        bot.send_chat_action(uid, 'typing')

        # –°–∫–∞—á–∏–≤–∞–µ–º
        file_info = bot.get_file(message.voice.file_id)
        downloaded_file = bot.download_file(file_info.file_path)

        # –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        voice_path = f"temp_voice_{uid}.ogg"
        with open(voice_path, 'wb') as f:
            f.write(downloaded_file)

        text = transcribe_voice(voice_path)

        try:
            os.remove(voice_path)
        except Exception:
            pass

        if text:
            handle_text_message(uid, text, message)
        else:
            bot.reply_to(message, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ —Ç–µ–∫—Å—Ç–æ–º ‚Äî —è —Å—Ä–µ–∞–≥–∏—Ä—É—é.")
    except Exception as e:
        log.error("Voice processing error: %s", e)
        bot.reply_to(message, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–∞. –ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç–æ–º.")

# ========= Text Handler =========
def maybe_offer_structural(uid: int, user_text: str, st: Dict[str, Any], patterns: List[str]):
    """–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø–µ—Ä–µ–π—Ç–∏ –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–º—É —Ä–∞–∑–±–æ—Ä—É, –µ—Å–ª–∏ –≤–∏–¥–∏–º —Ä–∏—Å–∫–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
    if should_suggest_deep_analysis(user_text, patterns) and st["intent"] != INTENT_ERR and not st["data"].get("struct_offer_shown"):
        st["data"]["struct_offer_shown"] = True
        save_state(uid, data=st["data"])
        summary = extract_problem_summary(st["data"].get("history", []))
        kb = types.InlineKeyboardMarkup().row(
            types.InlineKeyboardButton("–†–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ —à–∞–≥–∞–º", callback_data="start_error_flow"),
            types.InlineKeyboardButton("–ü–æ–∫–∞ –Ω–µ—Ç", callback_data="skip_error_flow")
        )
        bot.send_message(uid, f"{summary}\n\n–ü—Ä–µ–¥–ª–∞–≥–∞—é –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä: MERCEDES ‚Üí TOTE. –ù–∞—á–∏–Ω–∞–µ–º?", reply_markup=kb)

def handle_text_message(uid: int, text: str, original_message=None):
    st = load_state(uid)
    log.info("User %s: intent=%s step=%s text='%s'", uid, st["intent"], st["step"], text[:120])

    # history (user)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": text})
    st["data"]["history"] = history

    # Greeting: style selection
    if st["intent"] == INTENT_GREET and st["step"] == STEP_ASK_STYLE:
        if text.lower() in ("—Ç—ã", "–≤—ã"):
            st["data"]["style"] = text.lower()
            save_state(uid, intent=INTENT_FREE, step=STEP_FREE_INTRO, data=st["data"])
            bot.send_message(uid, f"–ü—Ä–∏–Ω—è—Ç–æ ({text}). –ß—Ç–æ —Å–µ–π—á–∞—Å –≤ —Ç—Ä–µ–π–¥–∏–Ω–≥–µ —Ö–æ—á–µ—Ç—Å—è –ø–æ–ø—Ä–∞–≤–∏—Ç—å?", reply_markup=MAIN_MENU)
        else:
            save_state(uid, data=st["data"])
            bot.send_message(uid, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ ¬´—Ç—ã¬ª –∏–ª–∏ ¬´–≤—ã¬ª.", reply_markup=style_kb())
        return

    # Structural flow
    if st["intent"] == INTENT_ERR:
        handle_structural_flow(uid, text, st)
        return

    # Free flow ‚Äî GPT
    patterns = detect_trading_patterns(text)
    decision = gpt_decide(uid, text, st)
    resp = decision.get("response_text", "–û–∫–µ–π. –í–æ–∑—å–º—ë–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏ —Ä–∞–∑–±–µ—Ä—ë–º –ø–æ —à–∞–≥–∞–º?")

    # history (assistant)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "assistant", "content": resp})

    merged = st["data"].copy()
    store = decision.get("store", {})
    if isinstance(store, dict):
        merged.update(store)
    merged["history"] = history

    new_intent = decision.get("intent", st["intent"])
    new_step = decision.get("next_step", st["step"])

    # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ—Å—á–∏—Ç–∞–ª–∞, —á—Ç–æ –Ω—É–∂–µ–Ω —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏–º —è–≤–Ω–æ
    if decision.get("is_structural", False):
        maybe_offer_structural(uid, text, st, patterns)

    save_state(uid, intent=new_intent, step=new_step, data=merged)

    if original_message:
        bot.reply_to(original_message, resp, reply_markup=MAIN_MENU)
    else:
        bot.send_message(uid, resp, reply_markup=MAIN_MENU)

    # –µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω—ã–µ ‚Äî —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–æ–∂–∏–º —Ä–∞–∑–±–æ—Ä
    maybe_offer_structural(uid, text, st, patterns)

@bot.message_handler(content_types=['text'])
def all_text(m: types.Message):
    handle_text_message(m.from_user.id, m.text, m)

# ========= Structural Flow =========
def handle_structural_flow(uid: int, text_in: str, st: Dict[str, Any]):
    # a) Error description
    if st["step"] == STEP_ERR_DESCR:
        new_data = st["data"].copy()
        new_data["error_description"] = text_in
        save_state(uid, intent=INTENT_ERR, step=STEP_MER_CTX, data=new_data)
        bot.send_message(uid, mer_prompt_for(STEP_MER_CTX))
        return

    # b) MERCEDES (4 —à–∞–≥–∞)
    if st["step"] in MER_ORDER:
        mer = st["data"].get("mer", {})
        mer[st["step"]] = text_in
        new_data = st["data"].copy()
        new_data["mer"] = mer

        idx = MER_ORDER.index(st["step"])
        if idx + 1 < len(MER_ORDER):
            next_step = MER_ORDER[idx + 1]
            save_state(uid, intent=INTENT_ERR, step=next_step, data=new_data)
            bot.send_message(uid, mer_prompt_for(next_step))
        else:
            save_state(uid, intent=INTENT_ERR, step=STEP_GOAL, data=new_data)
            bot.send_message(uid, "–¢–µ–ø–µ—Ä—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é —Ü–µ–ª—å: —á—Ç–æ –¥–µ–ª–∞–µ—à—å –≤–º–µ—Å—Ç–æ –ø—Ä–µ–∂–Ω–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è?")
        return

    # c) Goal
    if st["step"] == STEP_GOAL:
        new_data = st["data"].copy()
        new_data["goal"] = text_in
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_OPS, data=new_data)
        bot.send_message(uid, "–ù–∞–∑–æ–≤–∏ 2‚Äì3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —à–∞–≥–∞ –¥–ª—è –±–ª–∏–∂–∞–π—à–∏—Ö 3 —Å–¥–µ–ª–æ–∫ (–∫–æ—Ä–æ—Ç–∫–æ, —Å–ø–∏—Å–∫–æ–º).")
        return

    # d) TOTE - operations
    if st["step"] == STEP_TOTE_OPS:
        tote = st["data"].get("tote", {})
        tote["ops"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_TEST, data=new_data)
        bot.send_message(uid, "–ö–∞–∫ –ø–æ–π–º—ë—à—å, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å? –û–¥–∏–Ω –∫—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–æ–≤–µ—Ä–∫–∏.")
        return

    # e) TOTE - test
    if st["step"] == STEP_TOTE_TEST:
        tote = st["data"].get("tote", {})
        tote["test"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_EXIT, data=new_data)
        bot.send_message(uid, "–ß—Ç–æ —Å–¥–µ–ª–∞–µ—à—å, –µ—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫–∞–∂–µ—Ç ¬´–Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å¬ª?")
        return

    # f) TOTE - exit (final)
    if st["step"] == STEP_TOTE_EXIT:
        tote = st["data"].get("tote", {})
        tote["exit"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote

        mer = new_data.get('mer', {})
        summary = [
            "<b>–ò—Ç–æ–≥ —Ä–∞–∑–±–æ—Ä–∞</b>",
            f"–û—à–∏–±–∫–∞: {new_data.get('error_description', '‚Äî')}",
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {mer.get(STEP_MER_CTX, '‚Äî')}",
            f"–≠–º–æ—Ü–∏–∏: {mer.get(STEP_MER_EMO, '‚Äî')}",
            f"–ú—ã—Å–ª–∏: {mer.get(STEP_MER_THO, '‚Äî')}",
            f"–ü–æ–≤–µ–¥–µ–Ω–∏–µ: {mer.get(STEP_MER_BEH, '‚Äî')}",
            f"–¶–µ–ª—å: {new_data.get('goal', '‚Äî')}",
            f"–®–∞–≥–∏: {new_data.get('tote', {}).get('ops', '‚Äî')}",
            f"–ü—Ä–æ–≤–µ—Ä–∫–∞: {new_data.get('tote', {}).get('test', '‚Äî')}",
            f"–ï—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ: {new_data.get('tote', {}).get('exit', '‚Äî')}",
        ]
        save_state(uid, intent=INTENT_FREE, step=STEP_FREE_INTRO, data=new_data)
        bot.send_message(uid, "\n".join(summary), reply_markup=MAIN_MENU)
        bot.send_message(uid, "–î–æ–±–∞–≤–∏–º —ç—Ç–æ –≤ —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏ –∏–ª–∏ –∏–¥—ë–º –¥–∞–ª—å—à–µ?")

# ========= Callback =========
@bot.callback_query_handler(func=lambda call: True)
def on_callback(call: types.CallbackQuery):
    uid = call.from_user.id
    data = call.data or ""
    bot.answer_callback_query(call.id, "–û–∫")

    if data == "confirm_problem":
        st = load_state(uid)
        st["data"]["problem_confirmed"] = True
        save_state(uid, intent=INTENT_ERR, step=STEP_ERR_DESCR, data=st["data"])
        bot.send_message(uid, "–û—Ç–ª–∏—á–Ω–æ! –û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π: —á—Ç–æ, –≥–¥–µ, –∫–æ–≥–¥–∞, —á–µ–º –∫–æ–Ω—á–∏–ª–æ—Å—å?")
    elif data == "reject_problem":
        bot.send_message(uid, "–û–∫–µ–π, —É—Ç–æ—á–Ω–∏, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω–µ —Ç–∞–∫ ‚Äî —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é.", reply_markup=MAIN_MENU)
    elif data == "start_error_flow":
        st = load_state(uid)
        st["data"]["problem_confirmed"] = True
        save_state(uid, intent=INTENT_ERR, step=STEP_ERR_DESCR, data=st["data"])
        bot.send_message(uid, "–ù–∞—á–∏–Ω–∞–µ–º. –û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π: –≤—Ö–æ–¥, —Å—Ç–æ–ø/–ø–ª–∞–Ω, —á—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫.")
    elif data == "skip_error_flow":
        bot.send_message(uid, "–•–æ—Ä–æ—à–æ, –¥–µ—Ä–∂—É –≤ –≥–æ–ª–æ–≤–µ. –ï—Å–ª–∏ –ø–µ—Ä–µ–¥—É–º–∞–µ—à—å ‚Äî –Ω–∞–∂–º–∏ ¬´üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞¬ª.", reply_markup=MAIN_MENU)

# ========= Menu Handlers =========
MENU_BTNS = {
    "üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞": "error",
    "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é": "strategy",
    "üìÑ –ü–∞—Å–ø–æ—Ä—Ç": "passport",
    "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏": "weekpanel",
    "üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ": "panic",
    "ü§î –ù–µ –∑–Ω–∞—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å": "start_help",
}

@bot.message_handler(func=lambda m: m.text in MENU_BTNS.keys())
def handle_menu(m: types.Message):
    uid = m.from_user.id
    st = load_state(uid)
    label = m.text
    code = MENU_BTNS[label]

    # history
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": label})
    st["data"]["history"] = history

    if code == "error":
        save_state(uid, intent=INTENT_ERR, step=STEP_ERR_DESCR, data=st["data"])
        bot.send_message(uid, "–û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏: –≥–¥–µ/–∫–æ–≥–¥–∞, –≤—Ö–æ–¥/—Å—Ç–æ–ø/–ø–ª–∞–Ω, —á—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫.")
    elif code == "start_help":
        bot.send_message(uid, "–ü—Ä–µ–¥–ª–∞–≥–∞—é —Ç–∞–∫: 1) —Ä–∞–∑–±–æ—Ä –æ—à–∏–±–∫–∏ (–±—ã—Å—Ç—Ä–æ), 2) —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏, 3) —Å–∫–µ–ª–µ—Ç –¢–°. –° —á–µ–≥–æ –Ω–∞—á–Ω—ë–º?", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])
    else:
        bot.send_message(uid, "–û–∫. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —É—Å–∫–æ—Ä–∏—Ç—å—Å—è ‚Äî –Ω–∞–∂–º–∏ ¬´üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞¬ª.", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])

# ========= Webhook / Health =========
def _now_iso():
    return datetime.now(timezone.utc).isoformat()

@app.get("/")
def root():
    return jsonify({"ok": True, "time": _now_iso()})

@app.get("/health")
def health():
    return jsonify({"status": "ok", "time": _now_iso()})

@app.get("/version")
def version_api():
    return jsonify({
        "version": BOT_VERSION,
        "code_hash": get_code_version(),
        "status": "running",
        "timestamp": _now_iso()
    })

@app.get("/status")
def status():
    return jsonify({"ok": True, "time": _now_iso(), "version": BOT_VERSION})

@app.post(f"/{WEBHOOK_PATH}")
def webhook():
    if request.headers.get("X-Telegram-Bot-Api-Secret-Token") != TG_SECRET:
        abort(401)
    if request.content_length and request.content_length > MAX_BODY:
        abort(413, description="Body too large")

    body = request.get_data()
    if not body:
        abort(400, description="Empty body")

    try:
        json_str = body.decode("utf-8")
        update = telebot.types.Update.de_json(json_str)
        if update is None:
            log.error("Failed to parse update: %s", json_str)
            abort(400, description="Invalid update format")

        bot.process_new_updates([update])
        return "OK", 200
    except Exception as e:
        log.error("Webhook processing error: %s", e)
        abort(500)

def setup_webhook():
    try:
        bot.remove_webhook()
        time.sleep(1)
        bot.set_webhook(
            url=f"{PUBLIC_URL}/{WEBHOOK_PATH}",
            secret_token=TG_SECRET,
            allowed_updates=["message", "callback_query"]
        )
        log.info("Webhook set to %s/%s", PUBLIC_URL, WEBHOOK_PATH)
    except Exception as e:
        log.error("Webhook setup error: %s", e)

def cleanup_old_states(days: int = 30):
    """–£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    try:
        # –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
        db_exec(
            "DELETE FROM user_state WHERE updated_at < NOW() - make_interval(days => :days)",
            {"days": days}
        )
        log.info("Old user states cleanup done (>%s days).", days)
    except Exception as e:
        log.error("Cleanup error: %s", e)

def cleanup_scheduler():
    """–ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏"""
    while True:
        time.sleep(24 * 60 * 60)  # 24h
        cleanup_old_states(30)

# –ó–∞–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ (–ø–æ–¥ gunicorn)
_boot_done = False
@app.before_first_request
def boot():
    global _boot_done
    if _boot_done:
        return
    _boot_done = True
    init_db(silent=False)

    # —Å—Ç–∞—Ä—Ç —Ñ–æ–Ω–æ–≤–æ–≥–æ –∫–ª–∏–Ω–µ—Ä–∞
    try:
        th = threading.Thread(target=cleanup_scheduler, daemon=True)
        th.start()
    except Exception as e:
        log.error("Can't start cleanup thread: %s", e)

    if SET_WEBHOOK_FLAG:
        setup_webhook()

# –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ (dev). –ù–∞ Render –∏—Å–ø–æ–ª—å–∑—É–µ–º gunicorn –∫–æ–º–∞–Ω–¥–æ–π:
# gunicorn -w 1 -b 0.0.0.0:$PORT main:app
if __name__ == "__main__":
    # Dev-—Ä–µ–∂–∏–º: –ø–æ–¥–Ω–∏–º–∞–µ–º –≤—Å—ë —Å–∞–º–∏
    init_db(silent=False)
    try:
        th = threading.Thread(target=cleanup_scheduler, daemon=True)
        th.start()
    except Exception as e:
        log.error("Can't start cleanup thread: %s", e)

    if SET_WEBHOOK_FLAG:
        setup_webhook()

    port = int(os.getenv("PORT", "10000"))
    app.run(host="0.0.0.0", port=port)
