# main.py ‚Äî Innertrade Kai Mentor Bot
# –í–µ—Ä—Å–∏—è: 2025-09-22 (coach-mode)

import os
import json
import time
import logging
import threading
import hashlib
import re
from datetime import datetime, timezone
from typing import Any, Dict, Optional, List
from difflib import SequenceMatcher

import requests
from flask import Flask, request, abort, jsonify
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
import telebot
from telebot import types
from openai import OpenAI

# ========= Version =========
def get_code_version():
    try:
        with open(__file__, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()[:8]
    except Exception:
        return "unknown"

BOT_VERSION = f"2025-09-22-{get_code_version()}"

# ========= ENV =========
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "").strip()
PUBLIC_URL = os.getenv("PUBLIC_URL", "").strip()
WEBHOOK_PATH = os.getenv("WEBHOOK_PATH", "webhook").strip()
TG_SECRET = os.getenv("TG_WEBHOOK_SECRET", "").strip()
DATABASE_URL = os.getenv("DATABASE_URL", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()
OFFSCRIPT_ENABLED = os.getenv("OFFSCRIPT_ENABLED", "true").lower() == "true"
SET_WEBHOOK_FLAG = os.getenv("SET_WEBHOOK", "false").lower() == "true"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
MAX_BODY = int(os.getenv("MAX_BODY", "1000000"))
HIST_LIMIT = 12

# Validation
if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN is required")
if not DATABASE_URL:
    raise RuntimeError("DATABASE_URL is required")
if not PUBLIC_URL:
    raise RuntimeError("PUBLIC_URL is required")
if not WEBHOOK_PATH:
    raise RuntimeError("WEBHOOK_PATH is required")
if not TG_SECRET:
    raise RuntimeError("TG_WEBHOOK_SECRET is required")

# Logging
logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
log = logging.getLogger("innertrade")
log.info(f"Starting bot version: {BOT_VERSION}")

# ========= INTENTS/STEPS =========
INTENT_GREET = "greet"
INTENT_FREE = "free"
INTENT_ERR = "error"

STEP_ASK_STYLE = "ask_style"
STEP_FREE_INTRO = "free_intro"
STEP_ERR_DESCR = "err_describe"
STEP_MER_CTX = "mer_context"
STEP_MER_EMO = "mer_emotions"
STEP_MER_THO = "mer_thoughts"
STEP_MER_BEH = "mer_behavior"
STEP_GOAL = "goal_positive"
STEP_TOTE_OPS = "tote_ops"
STEP_TOTE_TEST = "tote_test"
STEP_TOTE_EXIT = "tote_exit"

MER_ORDER = [STEP_MER_CTX, STEP_MER_EMO, STEP_MER_THO, STEP_MER_BEH]

# ========= OpenAI =========
oai_client = None
openai_status = "disabled"
if OPENAI_API_KEY and OFFSCRIPT_ENABLED:
    try:
        oai_client = OpenAI(api_key=OPENAI_API_KEY)
        oai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5
        )
        openai_status = "active"
        log.info("OpenAI client initialized successfully")
    except Exception as e:
        log.error(f"OpenAI init error: {e}")
        oai_client = None
        openai_status = f"error: {e}"
else:
    log.warning("OpenAI disabled ‚Äî missing API key or OFFSCRIPT_ENABLED=false")
    openai_status = "disabled"

# ========= DB =========
engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=5,
    max_overflow=10,
    pool_timeout=30,
    pool_recycle=1800,
)

def db_exec(sql: str, params: Optional[Dict[str, Any]] = None):
    try:
        with engine.begin() as conn:
            return conn.execute(text(sql), params or {})
    except Exception as e:
        log.error("DB error: %s | SQL: %s | params: %s", e, sql, params)
        raise

def init_db(silent: bool = False):
    try:
        db_exec("""
        CREATE TABLE IF NOT EXISTS user_state(
            user_id BIGINT PRIMARY KEY,
            intent TEXT,
            step TEXT,
            data TEXT,
            updated_at TIMESTAMPTZ DEFAULT now()
        );
        """)
        db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_updated_at ON user_state(updated_at)")
        db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_intent_step ON user_state(intent, step)")
        if not silent:
            log.info("DB initialized")
    except Exception as e:
        log.error("init_db error (soft): %s", e)

# ========= State =========
def load_state(uid: int) -> Dict[str, Any]:
    try:
        row = db_exec(
            "SELECT intent, step, data FROM user_state WHERE user_id = :uid",
            {"uid": uid}
        ).mappings().first()
        if row:
            data = {}
            if row["data"]:
                try:
                    data = json.loads(row["data"])
                except Exception as e:
                    log.error("Failed to parse user data: %s", e)
                    data = {}
            return {
                "user_id": uid,
                "intent": row["intent"] or INTENT_GREET,
                "step": row["step"] or STEP_ASK_STYLE,
                "data": data
            }
    except Exception as e:
        log.error("load_state error: %s", e)
    return {"user_id": uid, "intent": INTENT_GREET, "step": STEP_ASK_STYLE, "data": {"history": []}}

def save_state(uid: int, intent: Optional[str] = None,
               step: Optional[str] = None, data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    cur = load_state(uid)
    new_intent = cur["intent"] if intent is None else intent
    new_step = cur["step"] if step is None else step
    new_data = cur["data"].copy()
    if data:
        new_data.update(data)
    payload = {
        "uid": uid,
        "intent": new_intent,
        "step": new_step,
        "data": json.dumps(new_data, ensure_ascii=False),
    }
    db_exec("""
        INSERT INTO user_state (user_id, intent, step, data, updated_at)
        VALUES (:uid, :intent, :step, :data, now())
        ON CONFLICT (user_id) DO UPDATE
        SET intent = EXCLUDED.intent,
            step   = EXCLUDED.step,
            data   = EXCLUDED.data,
            updated_at = now();
    """, payload)
    return {"user_id": uid, "intent": new_intent, "step": new_step, "data": new_data}

# ========= App & Bot =========
bot = telebot.TeleBot(TELEGRAM_TOKEN, parse_mode="HTML", threaded=False)
app = Flask(__name__)

# ========= Keyboards =========
def main_menu() -> types.ReplyKeyboardMarkup:
    kb = types.ReplyKeyboardMarkup(resize_keyboard=True)
    kb.row("üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞", "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
    kb.row("üìÑ –ü–∞—Å–ø–æ—Ä—Ç", "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏")
    kb.row("üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ", "ü§î –ù–µ –∑–Ω–∞ÃÅ—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å")
    return kb

MAIN_MENU = main_menu()

def style_kb() -> types.ReplyKeyboardMarkup:
    kb = types.ReplyKeyboardMarkup(resize_keyboard=True, one_time_keyboard=True)
    kb.row("—Ç—ã", "–≤—ã")
    return kb

# ========= Pattern Detection =========
def detect_trading_patterns(text: str) -> List[str]:
    patterns = {
        "remove_stop": ["—É–±–∏—Ä–∞—é —Å—Ç–æ–ø", "—É–±—Ä–∞–ª —Å—Ç–æ–ø", "—É–±—Ä–∞–ª–∞ —Å—Ç–æ–ø", "—Å–Ω–∏–º–∞—é —Å—Ç–æ–ø", "–±–µ–∑ —Å—Ç–æ–ø–∞"],
        "move_stop": ["–¥–≤–∏–≥–∞—é —Å—Ç–æ–ø", "–ø–µ—Ä–µ–¥–≤–∏–≥–∞—é —Å—Ç–æ–ø", "–ø–µ—Ä–µ—Å—Ç–∞–≤–ª—è—é —Å—Ç–æ–ø", "–æ—Ç–æ–¥–≤–∏–≥–∞–ª —Å—Ç–æ–ø", "–ø–µ—Ä–µ–Ω—ë—Å —Å—Ç–æ–ø"],
        "early_close": ["—Ä–∞–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–∫—Ä—ã–ª", "–∑–∞–∫—Ä—ã–ª —Ä–∞–Ω–æ", "–º–∞–ª–µ–Ω—å–∫–∏–π –ø–ª—é—Å –∑–∞–∫—Ä—ã–ª", "–≤—ã—Ö–æ–¥ —Ä–∞–Ω—å—à–µ"],
        "averaging": ["—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ", "–¥–æ–±–∞–≤–ª—è–ª—Å—è", "–¥–æ–∫—É–ø–∞–ª –ø—Ä–æ—Ç–∏–≤", "–¥–æ–ª–∏–≤–∞–ª—Å—è"],
        "break_even": ["–≤ –±–µ–∑—É–±—ã—Ç–æ–∫", "–ø–µ—Ä–µ–≤—ë–ª –≤ –Ω–æ–ª—å", "–ø–µ—Ä–µ–≤–æ–¥ –≤ –±–µ–∑—É–±—ã—Ç–æ–∫"],
        "small_profit": ["–º–∏–∑–µ—Ä–Ω—ã–π –ø–ª—é—Å", "–º–µ–ª–∫–∏–π –ø—Ä–æ—Ñ–∏—Ç", "–±—ã—Å—Ç—Ä–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è"],
        "self_doubt": ["—Å–æ–º–Ω–µ–≤–∞—é—Å—å", "–Ω–µ —É–≤–µ—Ä–µ–Ω", "—Å—Ç—Ä–µ—Å—Å—É—é", "–ø–∞–Ω–∏–∫–∞", "–≤–æ–ª–Ω–µ–Ω–∏–µ"],
        "fear_of_loss": ["—Å—Ç—Ä–∞—Ö –ø–æ—Ç–µ—Ä—å", "–±–æ—é—Å—å –ø–æ—Ç–µ—Ä—è—Ç—å", "–±–æ—é—Å—å —É–±—ã—Ç–∫–∞"],
        "fomo": ["—É–ø—É—Å—Ç–∏–ª", "–ø–æ–µ–∑–¥ —É–µ–¥–µ—Ç", "–±–µ–∑ –º–µ–Ω—è –ø–æ–π–¥—ë—Ç", "—É—Ö–æ–¥–∏—Ç –±–µ–∑ –º–µ–Ω—è"],
        "chaos": ["—Ö–∞–æ—Å", "—Ç–æ–ø—á—É—Å—å", "–Ω–µ –∑–Ω–∞—é —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å", "—Å–º—É—â–∞–ª–æ"],
        "rule_breaking": ["–Ω–∞—Ä—É—à–∞—é –ø—Ä–∞–≤–∏–ª–∞", "–æ—Ç–æ—à—ë–ª –æ—Ç –ø–ª–∞–Ω–∞", "–∏–≥–Ω–æ—Ä–∏—Ä—É—é –ø–ª–∞–Ω"]
    }
    tl = (text or "").lower()
    detected: List[str] = []
    for name, keys in patterns.items():
        if any(k in tl for k in keys):
            detected.append(name)
    return detected

def risky_patterns(pats: List[str]) -> bool:
    risk = {"remove_stop", "move_stop", "averaging", "early_close", "fomo"}
    return any(p in risk for p in pats) or len(pats) >= 2

# ========= Helpers =========
TEMPLATE_CHUNKS = [
    "–ø–æ–Ω–∏–º–∞—é", "—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å", "–≤–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å", "—Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å", "–¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä",
    "—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞", "–º–æ–∂–µ—à—å —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å", "–∫–∞–∫ —Ç—ã –æ–±—ã—á–Ω–æ",
    "—á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç", "–∫–∞–∫–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ", "–∫–∞–∫ –¥–æ–ª–≥–æ", "–≤ –∫–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö",
    "—ç—Ç–æ –ø–æ–º–æ–∂–µ—Ç", "–¥–∞–≤–∞–π —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º", "–±—ã–ª–æ –±—ã –ø–æ–ª–µ–∑–Ω–æ", "–ø–æ—Å—Ç–∞—Ä–∞–µ–º—Å—è", "—Å—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è"
]

def remove_template_phrases(text_in: str) -> str:
    text = text_in or ""
    for ph in TEMPLATE_CHUNKS:
        text = re.sub(rf"(?i)\b{re.escape(ph)}[^.!?]*[.!?]", " ", text)
    text = re.sub(r'\s+', ' ', text).strip(" ,.!?")
    return text

def anti_echo(user_text: str, model_text: str) -> str:
    u = (user_text or "").strip().lower()
    m = (model_text or "").strip()
    if len(u) < 15 or len(m) < 15:
        return m
    if SequenceMatcher(None, u, m.lower()).ratio() > 0.7:
        return "–°–∫–∞–∂—É –ø–æ-—Å–≤–æ–µ–º—É: " + m
    return m

def mer_prompt_for(step: str) -> str:
    prompts = {
        STEP_MER_CTX: "–ì–¥–µ/–∫–æ–≥–¥–∞ —ç—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å? –ö–æ—Ä–æ—Ç–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        STEP_MER_EMO: "–ß—Ç–æ –≤ –º–æ–º–µ–Ω—Ç–µ —á—É–≤—Å—Ç–≤—É–µ—à—å (2‚Äì3 —Å–ª–æ–≤–∞)?",
        STEP_MER_THO: "–ö–∞–∫–∏–µ –º—ã—Å–ª–∏ –º–µ–ª—å–∫–∞–ª–∏ (2‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã)?",
        STEP_MER_BEH: "–ß—Ç–æ —Å–¥–µ–ª–∞–ª —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏? –û–ø–∏—à–∏ –¥–µ–π—Å—Ç–≤–∏—è.",
    }
    return prompts.get(step, "–ü—Ä–æ–¥–æ–ª–∂–∏–º.")

def extract_problem_summary(history: List[Dict]) -> str:
    user_msgs = [m["content"] for m in history if m.get("role") == "user"]
    pats: List[str] = []
    for m in user_msgs:
        pats.extend(detect_trading_patterns(m))
    up = sorted(set(pats))
    parts = []
    if "self_doubt" in up: parts.append("–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –≤—Ö–æ–¥–∞")
    if "fear_of_loss" in up: parts.append("—Å—Ç—Ä–∞—Ö –ø–æ—Ç–µ—Ä—å")
    if "fomo" in up: parts.append("FOMO / —Å—Ç—Ä–∞—Ö —É–ø—É—Å—Ç–∏—Ç—å —Ö–æ–¥")
    if "remove_stop" in up or "move_stop" in up: parts.append("—Ç—Ä–æ–≥–∞–Ω–∏–µ/—Å–Ω—è—Ç–∏–µ —Å—Ç–æ–ø–∞")
    if "early_close" in up: parts.append("—Ä–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥")
    if "averaging" in up: parts.append("—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ –ø–æ–∑–∏—Ü–∏–∏")
    if "chaos" in up: parts.append("—Ö–∞–æ—Å/—Å–æ–º–Ω–µ–Ω–∏—è")
    if "rule_breaking" in up: parts.append("–Ω–∞—Ä—É—à–µ–Ω–∏–µ –ø–ª–∞–Ω–∞/–¢–°")
    return "–û—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã: " + (", ".join(parts) if parts else "–Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–∏—Ç—å –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ")

# ========= Voice =========
def transcribe_voice(audio_file_path: str) -> Optional[str]:
    if not oai_client:
        return None
    try:
        with open(audio_file_path, "rb") as audio_file:
            tr = oai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"
            )
            return tr.text
    except Exception as e:
        log.error("Voice transcription error: %s", e)
        return None

# ========= GPT (Coach-mode) =========
def gpt_decide(uid: int, text_in: str, st: Dict[str, Any]) -> Dict[str, Any]:
    """–°—Ç—Ä–æ–≥–æ –∫–æ—É—á–∏–Ω–≥–æ–≤—ã–π —Ä–µ–∂–∏–º: –Ω–∏–∫–∞–∫–∏—Ö —Å–æ–≤–µ—Ç–æ–≤/–¥–∏–∞–≥–Ω–æ–∑–æ–≤; 1 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –º–æ—Å—Ç–∏–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É."""
    fallback = {
        "next_step": st["step"],
        "intent": st["intent"],
        "response_text": "–í–æ–∑—å–º—ë–º —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä. –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –±—ã–ª–æ —Å–∏–≥–Ω–∞–ª–æ–º –∫ –≤—Ö–æ–¥—É –∏ —á—Ç–æ –±—ã–ª–æ –ø–ª–∞–Ω–æ–º –ø–æ —Å—Ç–æ–ø—É/–≤—ã—Ö–æ–¥—É?",
        "store": {},
        "is_structural": False
    }
    if not oai_client or not OFFSCRIPT_ENABLED:
        return fallback

    try:
        history = st["data"].get("history", [])
        style = st["data"].get("style", "—Ç—ã")
        patterns = detect_trading_patterns(text_in)
        patterns_text = ", ".join(patterns) if patterns else "–Ω–µ—Ç"

        system_prompt = f"""
–¢—ã ‚Äî –∫–æ—É—á-–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –ø–æ —Ç—Ä–µ–π–¥–∏–Ω–≥—É –ê–ª–µ–∫—Å. –ù–ï –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∏ –ù–ï –∞–Ω–∞–ª–∏—Ç–∏–∫.
–ó–∞–ø—Ä–µ—â–µ–Ω–æ: –¥–∞–≤–∞—Ç—å —Å–æ–≤–µ—Ç—ã, –¥–∏–∞–≥–Ω–æ–∑—ã, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (¬´—Å–¥–µ–ª–∞–π X¬ª, ¬´–∏—Å–ø–æ–ª—å–∑—É–π Y¬ª, ¬´–∑–∞–ø–∏—Å—ã–≤–∞–π Z¬ª), –æ–±–æ–±—â–µ–Ω–∏—è –∏ –º–æ—Ä–∞–ª–∏–∑–∞—Ç–æ—Ä—Å—Ç–≤–æ.
–¶–µ–ª—å: –ø–æ–º–æ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–æ–Ω—è—Ç—å —Å–≤–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω —á–µ—Ä–µ–∑ –≤–æ–ø—Ä–æ—Å—ã –∏ –ø—Ä–æ–≤–µ—Å—Ç–∏ –µ–≥–æ —á–µ—Ä–µ–∑ MERCEDES ‚Üí Goal ‚Üí TOTE.

–§–æ—Ä–º–∞ –æ—Ç–≤–µ—Ç–∞: –∫—Ä–∞—Ç–∫–æ (1‚Äì2 –∞–±–∑–∞—Ü–∞), –ø–æ –¥–µ–ª—É, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ –Ω–∞ ¬´{style}¬ª, –±–µ–∑ —à–∞–±–ª–æ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑.
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –∑–∞–¥–∞–π —Ä–æ–≤–Ω–æ –û–î–ò–ù —á—ë—Ç–∫–∏–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–¥–≤–∏–≥–∞–µ—Ç —Ä–∞–∑–±–æ—Ä –≤–ø–µ—Ä—ë–¥.
–ï—Å–ª–∏ —è–≤–Ω–æ –ø–æ—Ä–∞ –∏–¥—Ç–∏ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É ‚Äî –ø–æ—Å—Ç–∞–≤—å is_structural=true –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –º–æ—Å—Ç–∏–∫ –∫ —Ä–∞–∑–±–æ—Ä—É –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–µ–π—Å–∞ (–±–µ–∑ —Å–æ–≤–µ—Ç–æ–≤).

–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {patterns_text}

–í–µ—Ä–Ω–∏ JSON:
{{
  "next_step": "<–æ—Å—Ç–∞–≤—å —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —à–∞–≥–∞, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω>",
  "intent": "<–æ—Å—Ç–∞–≤—å —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω>",
  "response_text": "<–∫—Ä–∞—Ç–∫–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –º–æ—Å—Ç–∏–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –±–µ–∑ —Å–æ–≤–µ—Ç–æ–≤>",
  "store": {{}},
  "is_structural": <true|false>
}}
""".strip()

        msgs = [{"role": "system", "content": system_prompt}]
        for h in history[-HIST_LIMIT:]:
            if h.get("role") in ("user", "assistant") and isinstance(h.get("content"), str):
                msgs.append({"role": h["role"], "content": h["content"]})
        msgs.append({"role": "user", "content": text_in})

        res = oai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=msgs,
            temperature=0.3,
            response_format={"type": "json_object"},
        )
        raw = res.choices[0].message.content or "{}"
        dec = json.loads(raw)

        if not isinstance(dec, dict):
            return fallback
        for k in ["next_step", "intent", "response_text", "store", "is_structural"]:
            if k not in dec:
                return fallback
        if not isinstance(dec.get("store"), dict):
            dec["store"] = {}
        if not isinstance(dec.get("is_structural"), bool):
            dec["is_structural"] = False

        dec["response_text"] = remove_template_phrases(anti_echo(text_in, dec["response_text"]))

        ban_words = ["–ø–æ–ø—Ä–æ–±—É–π", "–∏—Å–ø–æ–ª—å–∑—É–π", "–ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–π—Å—è", "–∑–∞–ø–∏—Å—ã–≤–∞–π", "—É—Å—Ç–∞–Ω–æ–≤–∏", "—Å–ª–µ–¥—É–π", "–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏", "—Å—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è"]
        if any(bw in dec["response_text"].lower() for bw in ban_words) or len(dec["response_text"]) < 10:
            dec["response_text"] = "–í–æ–∑—å–º—ë–º —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä. –ß—Ç–æ –±—ã–ª–æ –ø–ª–∞–Ω–æ–º –ø–æ –≤—Ö–æ–¥—É/—Å—Ç–æ–ø—É –∏ –≤ –∫–∞–∫–æ–π –º–æ–º–µ–Ω—Ç —Ç—ã –æ—Ç –Ω–µ–≥–æ –æ—Ç—Å—Ç—É–ø–∏–ª?"

        return dec

    except Exception as e:
        log.error("GPT decision error: %s", e)
        return fallback

# ========= Commands =========
@bot.message_handler(commands=["ping"])
def cmd_ping(m: types.Message):
    bot.reply_to(m, "pong")

@bot.message_handler(commands=["menu"])
def cmd_menu(m: types.Message):
    bot.send_message(m.chat.id, "–ú–µ–Ω—é:", reply_markup=MAIN_MENU)

@bot.message_handler(commands=["help"])
def cmd_help(m: types.Message):
    bot.reply_to(m, "–Ø –∫–æ—É—á –ø–æ —Ç–æ—Ä–≥–æ–≤–ª–µ. –ß–µ—Ä–µ–∑ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–º–æ–≥–∞—é —É–≤–∏–¥–µ—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –∏ –ø—Ä–æ–≤–µ—Å—Ç–∏ —Ä–∞–∑–±–æ—Ä: MERCEDES ‚Üí —Ü–µ–ª—å ‚Üí TOTE. –ù–∞—á–Ω–∏ —Å ¬´üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞¬ª –∏–ª–∏ –æ–ø–∏—à–∏ —Å–∏—Ç—É–∞—Ü–∏—é.", reply_markup=MAIN_MENU)

@bot.message_handler(commands=["version", "v"])
def cmd_version(m: types.Message):
    version_info = f"""üîÑ –í–µ—Ä—Å–∏—è –±–æ—Ç–∞: {BOT_VERSION}
üìù –•—ç—à –∫–æ–¥–∞: {get_code_version()}
üïí –í—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä–∞: {datetime.now(timezone.utc).isoformat()}
ü§ñ OpenAI: {openai_status}"""
    bot.reply_to(m, version_info)

@bot.message_handler(commands=["debug"])
def cmd_debug(m: types.Message):
    dbg = {
        "openai_available": bool(oai_client),
        "offscript_enabled": OFFSCRIPT_ENABLED,
        "has_api_key": bool(OPENAI_API_KEY),
        "model": OPENAI_MODEL,
        "openai_status": openai_status
    }
    bot.reply_to(m, f"<code>{json.dumps(dbg, ensure_ascii=False, indent=2)}</code>")

@bot.message_handler(commands=["status"])
def cmd_status(m: types.Message):
    uid = m.from_user.id
    st = load_state(uid)
    resp = {
        "ok": True,
        "time": datetime.now(timezone.utc).isoformat(),
        "intent": st["intent"],
        "step": st["step"],
        "db": "ok"
    }
    bot.reply_to(m, f"<code>{json.dumps(resp, ensure_ascii=False, indent=2)}</code>")

@bot.message_handler(commands=["reset", "start"])
def cmd_reset(m: types.Message):
    uid = m.from_user.id
    save_state(uid, intent=INTENT_GREET, step=STEP_ASK_STYLE, data={"history": [], "style_set": False})
    bot.send_message(uid, f"üëã –ü—Ä–∏–≤–µ—Ç, {m.from_user.first_name or '—Ç—Ä–µ–π–¥–µ—Ä'}!\n–ö–∞–∫ —É–¥–æ–±–Ω–µ–µ –æ–±—Ä–∞—â–∞—Ç—å—Å—è ‚Äî <b>—Ç—ã</b> –∏–ª–∏ <b>–≤—ã</b>? (–Ω–∞–ø–∏—à–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ)", reply_markup=style_kb())

# ========= Structural Offer =========
def offer_structural(uid: int, st: Dict[str, Any]):
    if st["data"].get("struct_offer_shown"):
        return
    st["data"]["struct_offer_shown"] = True
    save_state(uid, data=st["data"])
    summary = extract_problem_summary(st["data"].get("history", []))
    kb = types.InlineKeyboardMarkup().row(
        types.InlineKeyboardButton("–†–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ —à–∞–≥–∞–º", callback_data="start_error_flow"),
        types.InlineKeyboardButton("–ü–æ–∫–∞ –Ω–µ—Ç", callback_data="skip_error_flow")
    )
    bot.send_message(uid, f"{summary}\n\n–ü—Ä–µ–¥–ª–∞–≥–∞—é –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä: MERCEDES ‚Üí TOTE. –ù–∞—á–∏–Ω–∞–µ–º?", reply_markup=kb)

# ========= Text =========
@bot.message_handler(content_types=['text'])
def all_text(m: types.Message):
    handle_text_message(m.from_user.id, m.text, m)

def handle_text_message(uid: int, text: str, original_message=None):
    st = load_state(uid)
    log.info("User %s: intent=%s step=%s text='%s'", uid, st["intent"], st["step"], text[:150])

    # history (user)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": text})
    st["data"]["history"] = history

    # guard: –µ—Å–ª–∏ —Å—Ç–∏–ª—å —É–∂–µ –≤—ã–±—Ä–∞–Ω, –Ω–æ –ø–æ –æ—à–∏–±–∫–µ –º—ã –≤ GREET/ASK_STYLE ‚Äî –ø–æ—á–∏–Ω–∏–º —Å—Ç–µ–π—Ç –Ω–∞ –ª–µ—Ç—É
    if st["intent"] == INTENT_GREET and st["step"] == STEP_ASK_STYLE and st["data"].get("style"):
        st["data"]["style_set"] = True
        st = save_state(uid, intent=INTENT_FREE, step=STEP_FREE_INTRO, data=st["data"])

    # Greeting: –≤—ã–±–æ—Ä —Å—Ç–∏–ª—è
    if st["intent"] == INTENT_GREET and st["step"] == STEP_ASK_STYLE:
        if text.lower() in ("—Ç—ã", "–≤—ã"):
            st["data"]["style"] = text.lower()
            st["data"]["style_set"] = True
            save_state(uid, intent=INTENT_FREE, step=STEP_FREE_INTRO, data=st["data"])
            bot.send_message(uid, f"–ü—Ä–∏–Ω—è—Ç–æ ({text}). –ß—Ç–æ —Å–µ–π—á–∞—Å —Ö–æ—á–µ—Ç—Å—è –ø–æ–ø—Ä–∞–≤–∏—Ç—å –≤ —Ç—Ä–µ–π–¥–∏–Ω–≥–µ?", reply_markup=MAIN_MENU)
        else:
            save_state(uid, data=st["data"])
            bot.send_message(uid, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ ¬´—Ç—ã¬ª –∏–ª–∏ ¬´–≤—ã¬ª.", reply_markup=style_kb())
        return

    # Structural flow
    if st["intent"] == INTENT_ERR:
        handle_structural_flow(uid, text, st)
        return

    # Free flow ‚Äî GPT (–∫–æ—É—á)
    patterns = detect_trading_patterns(text)
    decision = gpt_decide(uid, text, st)
    resp = decision.get("response_text") or "–î–∞–≤–∞–π –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ: —á—Ç–æ –±—ã–ª–æ –ø–ª–∞–Ω–æ–º –ø–æ –≤—Ö–æ–¥—É/—Å—Ç–æ–ø—É –∏ –≥–¥–µ —Ç—ã –æ—Ç –Ω–µ–≥–æ –æ—Ç–æ—à—ë–ª?"

    # history (assistant)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "assistant", "content": resp})

    merged = st["data"].copy()
    store = decision.get("store", {})
    if isinstance(store, dict):
        merged.update(store)
    merged["history"] = history

    new_intent = decision.get("intent") or st["intent"]
    new_step = decision.get("next_step") or st["step"]

    st_after = save_state(uid, intent=new_intent, step=new_step, data=merged)

    if original_message:
        bot.reply_to(original_message, resp, reply_markup=MAIN_MENU)
    else:
        bot.send_message(uid, resp, reply_markup=MAIN_MENU)

    if decision.get("is_structural", False) or risky_patterns(patterns):
        offer_structural(uid, st_after)

# ========= Structural Flow =========
def handle_structural_flow(uid: int, text_in: str, st: Dict[str, Any]):
    # a) –æ–ø–∏—Å–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
    if st["step"] == STEP_ERR_DESCR:
        new_data = st["data"].copy()
        new_data["error_description"] = text_in
        save_state(uid, intent=INTENT_ERR, step=STEP_MER_CTX, data=new_data)
        bot.send_message(uid, mer_prompt_for(STEP_MER_CTX))
        return

    # b) MERCEDES
    if st["step"] in MER_ORDER:
        mer = st["data"].get("mer", {})
        mer[st["step"]] = text_in
        new_data = st["data"].copy()
        new_data["mer"] = mer

        idx = MER_ORDER.index(st["step"])
        if idx + 1 < len(MER_ORDER):
            nxt = MER_ORDER[idx + 1]
            save_state(uid, intent=INTENT_ERR, step=nxt, data=new_data)
            bot.send_message(uid, mer_prompt_for(nxt))
        else:
            save_state(uid, intent=INTENT_ERR, step=STEP_GOAL, data=new_data)
            bot.send_message(uid, "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é —Ü–µ–ª—å: —á—Ç–æ –¥–µ–ª–∞–µ—à—å –≤–º–µ—Å—Ç–æ –ø—Ä–µ–∂–Ω–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è?")
        return

    # c) Goal
    if st["step"] == STEP_GOAL:
        new_data = st["data"].copy()
        new_data["goal"] = text_in
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_OPS, data=new_data)
        bot.send_message(uid, "–ù–∞–∑–æ–≤–∏ 2‚Äì3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —à–∞–≥–∞ –¥–ª—è –±–ª–∏–∂–∞–π—à–∏—Ö 3 —Å–¥–µ–ª–æ–∫ (–∫–æ—Ä–æ—Ç–∫–æ, —Å–ø–∏—Å–∫–æ–º).")
        return

    # d) TOTE - ops
    if st["step"] == STEP_TOTE_OPS:
        tote = st["data"].get("tote", {})
        tote["ops"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_TEST, data=new_data)
        bot.send_message(uid, "–ö–∞–∫ –ø–æ–π–º—ë—à—å, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å? –û–¥–∏–Ω –ø—Ä–æ—Å—Ç–æ–π –∫—Ä–∏—Ç–µ—Ä–∏–π.")
        return

    # e) TOTE - test
    if st["step"] == STEP_TOTE_TEST:
        tote = st["data"].get("tote", {})
        tote["test"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_EXIT, data=new_data)
        bot.send_message(uid, "–ß—Ç–æ —Å–¥–µ–ª–∞–µ—à—å, –µ—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫–∞–∂–µ—Ç ¬´–Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å¬ª?")
        return

    # f) TOTE - exit
    if st["step"] == STEP_TOTE_EXIT:
        tote = st["data"].get("tote", {})
        tote["exit"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote

        mer = new_data.get('mer', {})
        summary = [
            "<b>–ò—Ç–æ–≥ —Ä–∞–∑–±–æ—Ä–∞</b>",
            f"–û—à–∏–±–∫–∞: {new_data.get('error_description', '‚Äî')}",
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {mer.get(STEP_MER_CTX, '‚Äî')}",
            f"–≠–º–æ—Ü–∏–∏: {mer.get(STEP_MER_EMO, '‚Äî')}",
            f"–ú—ã—Å–ª–∏: {mer.get(STEP_MER_THO, '‚Äî')}",
            f"–ü–æ–≤–µ–¥–µ–Ω–∏–µ: {mer.get(STEP_MER_BEH, '‚Äî')}",
            f"–¶–µ–ª—å: {new_data.get('goal', '‚Äî')}",
            f"–®–∞–≥–∏: {new_data.get('tote', {}).get('ops', '‚Äî')}",
            f"–ü—Ä–æ–≤–µ—Ä–∫–∞: {new_data.get('tote', {}).get('test', '‚Äî')}",
            f"–ï—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ: {new_data.get('tote', {}).get('exit', '‚Äî')}",
        ]
        save_state(uid, intent=INTENT_FREE, step=STEP_FREE_INTRO, data=new_data)
        bot.send_message(uid, "\n".join(summary), reply_markup=MAIN_MENU)
        bot.send_message(uid, "–î–æ–±–∞–≤–∏–º —ç—Ç–æ –≤ —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏ –∏–ª–∏ –∏–¥—ë–º –¥–∞–ª—å—à–µ?")

# ========= Callbacks =========
@bot.callback_query_handler(func=lambda call: True)
def on_callback(call: types.CallbackQuery):
    uid = call.from_user.id
    data = call.data or ""
    bot.answer_callback_query(call.id, "–û–∫")

    if data == "start_error_flow":
        st = load_state(uid)
        st["data"]["problem_confirmed"] = True
        save_state(uid, intent=INTENT_ERR, step=STEP_ERR_DESCR, data=st["data"])
        bot.send_message(uid, "–ù–∞—á–∏–Ω–∞–µ–º —Ä–∞–∑–±–æ—Ä. –û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π: –≤—Ö–æ–¥/–ø–ª–∞–Ω, –≥–¥–µ –æ—Ç—Å—Ç—É–ø–∏–ª, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å –≤ –∏—Ç–æ–≥–µ.")
    elif data == "skip_error_flow":
        bot.send_message(uid, "–•–æ—Ä–æ—à–æ. –í–µ—Ä–Ω—ë–º—Å—è –∫ —ç—Ç–æ–º—É, –∫–æ–≥–¥–∞ –±—É–¥–µ—à—å –≥–æ—Ç–æ–≤.", reply_markup=MAIN_MENU)

# ========= Menu =========
MENU_BTNS = {
    "üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞": "error",
    "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é": "strategy",
    "üìÑ –ü–∞—Å–ø–æ—Ä—Ç": "passport",
    "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏": "weekpanel",
    "üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ": "panic",
    "ü§î –ù–µ –∑–Ω–∞ÃÅ—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å": "start_help",
}

@bot.message_handler(func=lambda m: m.text in MENU_BTNS.keys())
def handle_menu(m: types.Message):
    uid = m.from_user.id
    st = load_state(uid)
    label = m.text
    code = MENU_BTNS[label]

    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": label})
    st["data"]["history"] = history

    if code == "error":
        save_state(uid, intent=INTENT_ERR, step=STEP_ERR_DESCR, data=st["data"])
        bot.send_message(uid, "–û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–µ–π—Å –æ—à–∏–±–∫–∏: –≥–¥–µ/–∫–æ–≥–¥–∞, –≤—Ö–æ–¥/—Å—Ç–æ–ø/–ø–ª–∞–Ω, —á—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫.")
    elif code == "start_help":
        bot.send_message(uid, "–ü–ª–∞–Ω: 1) –±—ã—Å—Ç—Ä—ã–π —Ä–∞–∑–±–æ—Ä –æ—à–∏–±–∫–∏, 2) —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏, 3) —Å–∫–µ–ª–µ—Ç –¢–°. –° —á–µ–≥–æ –Ω–∞—á–Ω—ë–º?", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])
    else:
        bot.send_message(uid, "–û–∫. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —É—Å–∫–æ—Ä–∏—Ç—å—Å—è ‚Äî –Ω–∞–∂–º–∏ ¬´üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞¬ª.", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])

# ========= HTTP =========
def _now_iso():
    return datetime.now(timezone.utc).isoformat()

@app.get("/")
def root():
    return jsonify({"ok": True, "time": _now_iso()})

@app.get("/health")
def health():
    return jsonify({"status": "ok", "time": _now_iso()})

@app.get("/version")
def version_api():
    return jsonify({
        "version": BOT_VERSION,
        "code_hash": get_code_version(),
        "status": "running",
        "timestamp": _now_iso()
    })

@app.get("/status")
def status():
    return jsonify({"ok": True, "time": _now_iso(), "version": BOT_VERSION})

@app.post(f"/{WEBHOOK_PATH}")
def webhook():
    if request.headers.get("X-Telegram-Bot-Api-Secret-Token") != TG_SECRET:
        abort(401)
    if request.content_length and request.content_length > MAX_BODY:
        abort(413, description="Body too large")
    body = request.get_data()
    if not body:
        abort(400, description="Empty body")
    try:
        update = telebot.types.Update.de_json(body.decode("utf-8"))
        if update is None:
            log.error("Failed to parse update")
            abort(400, description="Invalid update")
        bot.process_new_updates([update])
        return "OK", 200
    except Exception as e:
        log.error("Webhook processing error: %s", e)
        abort(500)

# ========= Maintenance =========
def cleanup_old_states(days: int = 30):
    try:
        db_exec("DELETE FROM user_state WHERE updated_at < NOW() - make_interval(days => :days)", {"days": days})
        log.info("Old user states cleanup done (> %s days).", days)
    except Exception as e:
        log.error("Cleanup error: %s", e)

def cleanup_scheduler():
    while True:
        time.sleep(24 * 60 * 60)
        cleanup_old_states(30)

# ========= Boot (Flask 3.x) =========
_boot_done = False

@app.before_serving
def boot():
    global _boot_done
    if _boot_done:
        return
    _boot_done = True

    init_db(silent=False)
    try:
        th = threading.Thread(target=cleanup_scheduler, daemon=True)
        th.start()
    except Exception as e:
        log.error("Can't start cleanup thread: %s", e)

    if SET_WEBHOOK_FLAG:
        try:
            bot.remove_webhook()
            time.sleep(1)
            bot.set_webhook(
                url=f"{PUBLIC_URL}/{WEBHOOK_PATH}",
                secret_token=TG_SECRET,
                allowed_updates=["message", "callback_query"]
            )
            log.info("Webhook set to %s/%s", PUBLIC_URL, WEBHOOK_PATH)
        except Exception as e:
            log.error("Webhook setup error: %s", e)

# ========= Dev run =========
if __name__ == "__main__":
    init_db(silent=False)
    try:
        th = threading.Thread(target=cleanup_scheduler, daemon=True)
        th.start()
    except Exception as e:
        log.error("Can't start cleanup thread: %s", e)
    port = int(os.getenv("PORT", "10000"))
    app.run(host="0.0.0.0", port=port)
