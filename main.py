# main.py ‚Äî Innertrade Kai Mentor Bot (Production Ready)
# –í–µ—Ä—Å–∏—è: 2025-09-02-mentor-v3

import os
import json
import time
import logging
import threading
import re
from datetime import datetime, timezone
from typing import Any, Dict, Optional, List, Tuple
from difflib import SequenceMatcher

import requests
from flask import Flask, request, abort, jsonify
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
import telebot
from telebot import types
from openai import OpenAI

# ========= ENV =========
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "").strip()
PUBLIC_URL = os.getenv("PUBLIC_URL", "").strip()
WEBHOOK_PATH = os.getenv("WEBHOOK_PATH", "webhook").strip()
TG_SECRET = os.getenv("TG_WEBHOOK_SECRET", "").strip()
DATABASE_URL = os.getenv("DATABASE_URL", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()
OFFSCRIPT_ENABLED = os.getenv("OFFSCRIPT_ENABLED", "true").lower() == "true"
SET_WEBHOOK_FLAG = os.getenv("SET_WEBHOOK", "false").lower() == "true"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
MAX_BODY = int(os.getenv("MAX_BODY", "1000000"))
HIST_LIMIT = 12

# Validation
if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN is required")
if not DATABASE_URL:
    raise RuntimeError("DATABASE_URL is required")
if not PUBLIC_URL:
    raise RuntimeError("PUBLIC_URL is required")
if not WEBHOOK_PATH:
    raise RuntimeError("WEBHOOK_PATH is required")
if not TG_SECRET:
    raise RuntimeError("TG_WEBHOOK_SECRET is required")

# Logging
logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
log = logging.getLogger("innertrade")

# ========= INTENTS/STEPS =========
INTENT_GREET = "greet"
INTENT_FREE = "free"
INTENT_ERR = "error"

STEP_ASK_STYLE = "ask_style"
STEP_FREE_INTRO = "free_intro"
STEP_ERR_DESCR = "err_describe"
STEP_MER_CTX = "mer_context"
STEP_MER_EMO = "mer_emotions"
STEP_MER_THO = "mer_thoughts"
STEP_MER_BEH = "mer_behavior"
STEP_GOAL = "goal_positive"
STEP_TOTE_OPS = "tote_ops"
STEP_TOTE_TEST = "tote_test"
STEP_TOTE_EXIT = "tote_exit"
STEP_DONE = "done"

MER_ORDER = [STEP_MER_CTX, STEP_MER_EMO, STEP_MER_THO, STEP_MER_BEH]

# ========= OpenAI =========
oai_client = None
if OPENAI_API_KEY and OFFSCRIPT_ENABLED:
    try:
        oai_client = OpenAI(api_key=OPENAI_API_KEY)
        log.info("OpenAI client initialized")
    except Exception as e:
        log.error("OpenAI init error: %s", e)
        oai_client = None

# ========= DB =========
engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=5,
    max_overflow=10,
    pool_timeout=30,
    pool_recycle=1800,
)

def db_exec(sql: str, params: Optional[Dict[str, Any]] = None):
    try:
        with engine.begin() as conn:
            return conn.execute(text(sql), params or {})
    except Exception as e:
        log.error("DB error: %s | SQL: %s | params: %s", e, sql, params)
        raise

def init_db():
    db_exec("""
    CREATE TABLE IF NOT EXISTS user_state(
        user_id BIGINT PRIMARY KEY,
        intent TEXT,
        step TEXT,
        data TEXT,
        updated_at TIMESTAMPTZ DEFAULT now()
    );""")
    db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_updated_at ON user_state(updated_at)")
    db_exec("CREATE INDEX IF NOT EXISTS idx_user_state_intent_step ON user_state(intent, step)")
    log.info("DB initialized")

# ========= State Management =========
def load_state(uid: int) -> Dict[str, Any]:
    try:
        row = db_exec(
            "SELECT intent, step, data FROM user_state WHERE user_id = :uid",
            {"uid": uid}
        ).mappings().first()
        if row:
            data = {}
            if row["data"]:
                try:
                    data = json.loads(row["data"])
                except Exception as e:
                    log.error("Failed to parse user data: %s", e)
                    data = {}
            return {
                "user_id": uid,
                "intent": row["intent"] or INTENT_GREET,
                "step": row["step"] or STEP_ASK_STYLE,
                "data": data
            }
    except Exception as e:
        log.error("load_state error: %s", e)

    return {"user_id": uid, "intent": INTENT_GREET, "step": STEP_ASK_STYLE, "data": {"history": []}}

def save_state(uid: int, intent: Optional[str] = None,
               step: Optional[str] = None, data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    cur = load_state(uid)
    new_intent = intent if intent is not None else cur["intent"]
    new_step = step if step is not None else cur["step"]
    new_data = cur["data"].copy()
    if data:
        new_data.update(data)

    payload = {
        "uid": uid,
        "intent": new_intent,
        "step": new_step,
        "data": json.dumps(new_data, ensure_ascii=False),
    }
    db_exec("""
        INSERT INTO user_state (user_id, intent, step, data, updated_at)
        VALUES (:uid, :intent, :step, :data, now())
        ON CONFLICT (user_id) DO UPDATE
        SET intent = EXCLUDED.intent,
            step   = EXCLUDED.step,
            data   = EXCLUDED.data,
            updated_at = now();
    """, payload)

    return {"user_id": uid, "intent": new_intent, "step": new_step, "data": new_data}

# ========= Bot & Flask =========
bot = telebot.TeleBot(TELEGRAM_TOKEN, parse_mode="HTML", threaded=False)
app = Flask(__name__)

# ========= Keyboards =========
def main_menu() -> types.ReplyKeyboardMarkup:
    kb = types.ReplyKeyboardMarkup(resize_keyboard=True)
    kb.row("üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞", "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
    kb.row("üìÑ –ü–∞—Å–ø–æ—Ä—Ç", "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏")
    kb.row("üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ", "ü§î –ù–µ –∑–Ω–∞—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å")
    return kb

MAIN_MENU = main_menu()

def style_kb() -> types.ReplyKeyboardMarkup:
    kb = types.ReplyKeyboardMarkup(resize_keyboard=True, one_time_keyboard=True)
    kb.row("—Ç—ã", "–≤—ã")
    return kb

# ========= Pattern Detection =========
def detect_trading_patterns(text: str) -> List[str]:
    """–î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª"""
    patterns = {
        "remove_stop": ["—É–±–∏—Ä–∞—é —Å—Ç–æ–ø", "—É–±–∏—Ä–∞—é —Å—Ç–æ–ø-–ª–æ—Å—Å", "—Å–Ω–∏–º–∞—é —Å—Ç–æ–ø"],
        "move_stop": ["–¥–≤–∏–≥–∞—é —Å—Ç–æ–ø", "–ø–µ—Ä–µ–¥–≤–∏–≥–∞—é —Å—Ç–æ–ø", "–ø–µ—Ä–µ—Å—Ç–∞–≤–ª—è—é —Å—Ç–æ–ø"],
        "early_close": ["–∑–∞–∫—Ä—ã—Ç—å –ø–æ–∑–∏—Ü–∏—é", "—Ä–∞–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–∫—Ä—ã—Ç—å"],
        "averaging": ["—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ", "–¥–æ–∫—É–ø–∞—Ç—å", "–¥–æ–±–∞–≤–ª—è—Ç—å—Å—è"],
        "break_even": ["–±–µ–∑—É–±—ã—Ç–æ–∫", "–≤ –Ω–æ–ª—å", "–±–µ–∑ —É–±—ã—Ç–∫–∞"],
        "small_profit": ["–º–µ–ª–∫–∏–π –ø—Ä–æ—Ñ–∏—Ç", "–Ω–µ–±–æ–ª—å—à—É—é –ø—Ä–∏–±—ã–ª—å", "—Å–∫–æ—Ä–µ–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å"],
        "self_doubt": ["–Ω–µ —É–≤–µ—Ä–µ–Ω", "—Å–æ–º–Ω–µ–≤–∞—é—Å—å", "–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"],
        "fear_of_loss": ["—Å—Ç—Ä–∞—Ö –ø–æ—Ç–µ—Ä—è—Ç—å", "–±–æ—é—Å—å –ø–æ—Ç–µ—Ä—è—Ç—å", "—Å—Ç—Ä–∞—Ö —É–±—ã—Ç–∫–∞"]
    }
    
    detected = []
    text_lower = text.lower()
    for pattern, keywords in patterns.items():
        if any(keyword in text_lower for keyword in keywords):
            detected.append(pattern)
    
    return detected

def should_suggest_deep_analysis(text: str, patterns: List[str]) -> bool:
    """–ö–æ–≥–¥–∞ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å –≥–ª—É–±–æ–∫–∏–π —Ä–∞–∑–±–æ—Ä"""
    crisis_words = ["—Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏", "–¥–∞–≤–Ω–æ", "–Ω–µ –º–æ–≥—É", "–Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è", "–ø–æ—Å—Ç–æ—è–Ω–Ω–æ", "—Ä–µ–≥—É–ª—è—Ä–Ω–æ"]
    has_crisis = any(word in text.lower() for word in crisis_words)
    has_patterns = len(patterns) >= 2
    
    return has_crisis or has_patterns

# ========= Helpers =========
def anti_echo(user_text: str, model_text: str) -> str:
    u = (user_text or "").strip().lower()
    m = (model_text or "").strip()
    if len(u) < 15 or len(m) < 15:
        return m
    similarity = SequenceMatcher(None, u, m.lower()).ratio()
    if similarity > 0.7:
        return "–ü–æ–Ω—è–ª. –°–∫–∞–∂—É –ø–æ-—Å–≤–æ–µ–º—É: " + m
    return m

def mer_prompt_for(step: str) -> str:
    prompts = {
        STEP_MER_CTX: "–ö–û–ù–¢–ï–ö–°–¢. –í –∫–∞–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ —ç—Ç–æ –æ–±—ã—á–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç? –ß—Ç–æ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É–µ—Ç? (1‚Äì2 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
        STEP_MER_EMO: "–≠–ú–û–¶–ò–ò. –ß—Ç–æ —á—É–≤—Å—Ç–≤—É–µ—à—å –≤ –º–æ–º–µ–Ω—Ç –æ—à–∏–±–∫–∏? (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤)",
        STEP_MER_THO: "–ú–´–°–õ–ò. –ö–∞–∫–∏–µ —Ñ—Ä–∞–∑—ã –∫—Ä—É—Ç—è—Ç—Å—è –≤ –≥–æ–ª–æ–≤–µ? (1‚Äì2 –∫–æ—Ä–æ—Ç–∫–∏—Ö)",
        STEP_MER_BEH: "–ü–û–í–ï–î–ï–ù–ò–ï. –ß—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã –¥–µ–ª–∞–µ—à—å? –û–ø–∏—à–∏ –¥–µ–π—Å—Ç–≤–∏—è –≥–ª–∞–≥–æ–ª–∞–º–∏.",
    }
    return prompts.get(step, "–ü—Ä–æ–¥–æ–ª–∂–∏–º.")

# ========= Voice Handling =========
def transcribe_voice(audio_file_path: str) -> Optional[str]:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ Whisper"""
    if not oai_client:
        return None
        
    try:
        with open(audio_file_path, "rb") as audio_file:
            transcript = oai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"
            )
            return transcript.text
    except Exception as e:
        log.error("Voice transcription error: %s", e)
        return None

# ========= GPT Decision Maker =========
def gpt_decide(uid: int, text_in: str, st: Dict[str, Any]) -> Dict[str, Any]:
    fallback = {
        "next_step": st["step"],
        "intent": st["intent"],
        "response_text": "–ü–æ–Ω—è–ª. –ü—Ä–æ–¥–æ–ª–∂–∏–º.",
        "store": {},
        "is_structural": False
    }
    if not oai_client or not OFFSCRIPT_ENABLED:
        return fallback

    try:
        history = st["data"].get("history", [])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –∏ —Å—Ç–∏–ª–µ –æ–±—â–µ–Ω–∏—è
        style = st["data"].get("style", "—Ç—ã")
        patterns = detect_trading_patterns(text_in)
        patterns_text = ", ".join(patterns) if patterns else "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
        
        system_prompt = f"""
        –¢—ã ‚Äî —Ç—ë–ø–ª—ã–π –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –ø–æ —Ç—Ä–µ–π–¥–∏–Ω–≥—É –ø–æ –∏–º–µ–Ω–∏ –ê–ª–µ–∫—Å. –í–µ–¥–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é.
        –í—Å–µ–≥–¥–∞ –æ–±—Ä–∞—â–∞–π—Å—è –Ω–∞ {style}, –∫–∞–∫ –≤—ã–±—Ä–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å.
        
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {patterns_text}
        
        –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
        1. –ù–ò–ö–û–ì–î–ê –Ω–µ –Ω–∞—á–∏–Ω–∞–π –æ—Ç–≤–µ—Ç —Å —à–∞–±–ª–æ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑: "–ü–æ–Ω–∏–º–∞—é, —ç—Ç–æ...", "–Ø –ø–æ–Ω–∏–º–∞—é, —á—Ç–æ...", "–≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å..."
        2. –ù–ò–ö–û–ì–î–ê –Ω–µ —Å—Å—ã–ª–∞–π—Å—è –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —è–≤–Ω–æ
        3. –ù–ò–ö–û–ì–î–ê –Ω–µ –∑–∞–¥–∞–≤–∞–π —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã (–ø—Ä–æ "–∫–∞–∫ –¥–æ–ª–≥–æ" –∏–ª–∏ "–≤ –∫–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö")
        4. –í—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É –≤–º–µ—Å—Ç–æ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π
        5. –ü—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å—Ä–∞–∑—É –ø—Ä–µ–¥–ª–∞–≥–∞–π —Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π
        6. –ë—É–¥—å –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–º - –ø—Ä–µ–¥–ª–∞–≥–∞–π –≥–ª—É–±–æ–∫–∏–π —Ä–∞–∑–±–æ—Ä –ø—Ä–∏ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö
        7. –°–æ—Ö—Ä–∞–Ω—è–π empathetic —Ç–æ–Ω, –Ω–æ –±–µ–∑ —à–∞–±–ª–æ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
        8. –ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–º –æ–±—â–µ–Ω–∏–∏ (1-2 –∞–±–∑–∞—Ü–∞)
        9. –ü—Ä–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∫—Ä–∏–∑–∏—Å–∞ –ø–µ—Ä–µ—Ö–æ–¥–∏ –≤ —Ä–µ–∂–∏–º –ø–æ–¥–¥–µ—Ä–∂–∫–∏
        
        –û—Ç–≤–µ—Ç –æ—Ç–¥–∞–≤–∞–π —Å—Ç—Ä–æ–∫–∞ JSON —Å –∫–ª—é—á–∞–º–∏: next_step, intent, response_text, store(–æ–±—ä–µ–∫—Ç), is_structural(true/false).
        """

        msgs = [{"role": "system", "content": system_prompt}]
        for h in history[-HIST_LIMIT:]:
            if h.get("role") in ("user", "assistant") and isinstance(h.get("content"), str):
                msgs.append({"role": h["role"], "content": h["content"]})
        msgs.append({"role": "user", "content": text_in})

        res = oai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=msgs,
            temperature=0.3,
            response_format={"type": "json_object"},
        )
        raw = res.choices[0].message.content or "{}"
        dec = json.loads(raw)

        required = ["next_step", "intent", "response_text", "store", "is_structural"]
        if not all(k in dec for k in required):
            return fallback
        if not isinstance(dec.get("store"), dict):
            dec["store"] = {}
        if not isinstance(dec.get("is_structural"), bool):
            dec["is_structural"] = False

        dec["response_text"] = anti_echo(text_in, dec["response_text"])
        return dec

    except Exception as e:
        log.error("GPT decision error: %s", e)
        return fallback

# ========= Commands =========
@bot.message_handler(commands=["ping"])
def cmd_ping(m: types.Message):
    bot.reply_to(m, "pong")

@bot.message_handler(commands=["status"])
def cmd_status(m: types.Message):
    uid = m.from_user.id
    st = load_state(uid)
    response = {
        "ok": True,
        "time": datetime.now(timezone.utc).isoformat(),
        "intent": st["intent"],
        "step": st["step"],
        "db": "ok"
    }
    bot.reply_to(m, f"<code>{json.dumps(response, ensure_ascii=False, indent=2)}</code>")

@bot.message_handler(commands=["reset", "start"])
def cmd_reset(m: types.Message):
    uid = m.from_user.id
    save_state(uid, intent=INTENT_GREET, step=STEP_ASK_STYLE, data={"history": []})
    bot.send_message(
        uid,
        f"üëã –ü—Ä–∏–≤–µ—Ç, {m.from_user.first_name or '—Ç—Ä–µ–π–¥–µ—Ä'}!\n–ö–∞–∫ —É–¥–æ–±–Ω–µ–µ –æ–±—Ä–∞—â–∞—Ç—å—Å—è ‚Äî <b>—Ç—ã</b> –∏–ª–∏ <b>–≤—ã</b>? (–Ω–∞–ø–∏—à–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ)",
        reply_markup=style_kb()
    )

# ========= Media Handler =========
@bot.message_handler(content_types=['voice', 'audio'])
def handle_voice(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    try:
        uid = message.from_user.id
        bot.send_chat_action(uid, 'typing')
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        file_info = bot.get_file(message.voice.file_id)
        downloaded_file = bot.download_file(file_info.file_path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        voice_path = f"temp_voice_{uid}.ogg"
        with open(voice_path, 'wb') as f:
            f.write(downloaded_file)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
        text = transcribe_voice(voice_path)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        try:
            os.remove(voice_path)
        except:
            pass
        
        if text:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            handle_text_message(uid, text, message)
        else:
            bot.reply_to(message, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç–æ–º.")
            
    except Exception as e:
        log.error("Voice processing error: %s", e)
        bot.reply_to(message, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º.")

def handle_text_message(uid: int, text: str, original_message=None):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–æ–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è)"""
    st = load_state(uid)
    log.info("User %s: intent=%s step=%s text='%s'", uid, st["intent"], st["step"], text[:80])

    # Update history (user)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": text})
    st["data"]["history"] = history

    # Greeting: style selection
    if st["intent"] == INTENT_GREET and st["step"] == STEP_ASK_STYLE:
        if text.lower() in ("—Ç—ã", "–≤—ã"):
            st["data"]["style"] = text.lower()
            save_state(uid, intent=INTENT_FREE, step=STEP_FREE_INTRO, data=st["data"])
            bot.send_message(uid, f"–ü—Ä–∏–Ω—è—Ç–æ ({text}). –†–∞—Å—Å–∫–∞–∂–∏, —á—Ç–æ —Å–µ–π—á–∞—Å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ —Ç–≤–æ–µ–π —Ç–æ—Ä–≥–æ–≤–ª–µ?", reply_markup=MAIN_MENU)
        else:
            save_state(uid, data=st["data"])
            bot.send_message(uid, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ ¬´—Ç—ã¬ª –∏–ª–∏ ¬´–≤—ã¬ª.", reply_markup=style_kb())
        return

    # Structural flow
    if st["intent"] == INTENT_ERR:
        handle_structural_flow(uid, text, st)
        return

    # Free flow ‚Äî GPT
    patterns = detect_trading_patterns(text)
    suggest_analysis = should_suggest_deep_analysis(text, patterns)
    
    decision = gpt_decide(uid, text, st)
    resp = decision.get("response_text", "–ü–æ–Ω—è–ª.")

    # Update history (assistant)
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "assistant", "content": resp})

    merged = st["data"].copy()
    store = decision.get("store", {})
    if isinstance(store, dict):
        merged.update(store)
    merged["history"] = history

    new_intent = decision.get("intent", st["intent"])
    new_step = decision.get("next_step", st["step"])

    save_state(uid, intent=new_intent, step=new_step, data=merged)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
    if original_message:
        bot.reply_to(original_message, resp, reply_markup=MAIN_MENU)
    else:
        bot.send_message(uid, resp, reply_markup=MAIN_MENU)
    
    # –ü—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–º–æ—â–∏
    if suggest_analysis and new_intent != INTENT_ERR:
        bot.send_message(
            uid, 
            "–ü–æ—Ö–æ–∂–µ, —ç—Ç–æ —Å–∏—Å—Ç–µ–º–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞. –•–æ—á–µ—à—å —Ä–∞–∑–±–µ—Ä–µ–º –µ—ë –ø–æ–¥—Ä–æ–±–Ω–æ?",
            reply_markup=types.InlineKeyboardMarkup().row(
                types.InlineKeyboardButton("–î–∞, –¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º", callback_data="deep_analysis_yes"),
                types.InlineKeyboardButton("–ü–æ–∫–∞ –Ω–µ—Ç", callback_data="deep_analysis_no")
            )
        )

@bot.message_handler(content_types=['text'])
def all_text(m: types.Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    handle_text_message(m.from_user.id, m.text, m)

# ========= Structural Flow =========
def handle_structural_flow(uid: int, text_in: str, st: Dict[str, Any]):
    # a) Error description
    if st["step"] == STEP_ERR_DESCR:
        new_data = st["data"].copy()
        new_data["error_description"] = text_in
        save_state(uid, intent=INTENT_ERR, step=STEP_MER_CTX, data=new_data)
        bot.send_message(uid, mer_prompt_for(STEP_MER_CTX))
        return

    # b) MERCEDES (4 —à–∞–≥–∞)
    if st["step"] in MER_ORDER:
        mer = st["data"].get("mer", {})
        mer[st["step"]] = text_in
        new_data = st["data"].copy()
        new_data["mer"] = mer

        idx = MER_ORDER.index(st["step"])
        if idx + 1 < len(MER_ORDER):
            next_step = MER_ORDER[idx + 1]
            save_state(uid, intent=INTENT_ERR, step=next_step, data=new_data)
            bot.send_message(uid, mer_prompt_for(next_step))
        else:
            save_state(uid, intent=INTENT_ERR, step=STEP_GOAL, data=new_data)
            bot.send_message(uid, "–¢–µ–ø–µ—Ä—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π <b>–ø–æ–∑–∏—Ç–∏–≤–Ω—É—é —Ü–µ–ª—å</b>: —á—Ç–æ —Ö–æ—á–µ—à—å –¥–µ–ª–∞—Ç—å –≤–º–µ—Å—Ç–æ –ø—Ä–µ–∂–Ω–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è? (–æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)")
        return

    # c) Goal
    if st["step"] == STEP_GOAL:
        new_data = st["data"].copy()
        new_data["goal"] = text_in
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_OPS, data=new_data)
        bot.send_message(uid, "–û—Ç–ª–∏—á–Ω–æ. –ù–∞–∑–æ–≤–∏ 2‚Äì3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —à–∞–≥–∞ (–æ–ø–µ—Ä–∞—Ü–∏–∏), –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç —É–¥–µ—Ä–∂–∞—Ç—å —Ü–µ–ª—å –≤ –±–ª–∏–∂–∞–π—à–∏—Ö 3 —Å–¥–µ–ª–∫–∞—Ö.")
        return

    # d) TOTE - operations
    if st["step"] == STEP_TOTE_OPS:
        tote = st["data"].get("tote", {})
        tote["ops"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_TEST, data=new_data)
        bot.send_message(uid, "–ö–∞–∫ –ø–æ–π–º—ë—à—å, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å? –î–∞–π –æ–¥–∏–Ω –ø—Ä–æ—Å—Ç–æ–π –∫—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´3 —Å–¥–µ–ª–∫–∏ –ø–æ–¥—Ä—è–¥ –±–µ–∑ —Å–¥–≤–∏–≥–∞ —Å—Ç–æ–ø–∞¬ª).")
        return

    # e) TOTE - test
    if st["step"] == STEP_TOTE_TEST:
        tote = st["data"].get("tote", {})
        tote["test"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote
        save_state(uid, intent=INTENT_ERR, step=STEP_TOTE_EXIT, data=new_data)
        bot.send_message(uid, "–ß—Ç–æ —Å–¥–µ–ª–∞–µ—à—å, –µ—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫–∞–∂–µ—Ç ¬´–Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å¬ª? (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´—Å—Ç–æ–ø-–ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –∏ –ø–∞—É–∑–∞¬ª)")
        return

    # f) TOTE - exit (final)
    if st["step"] == STEP_TOTE_EXIT:
        tote = st["data"].get("tote", {})
        tote["exit"] = text_in
        new_data = st["data"].copy()
        new_data["tote"] = tote

        summary = [
            "<b>–ò—Ç–æ–≥ —Ä–∞–∑–±–æ—Ä–∞</b>",
            f"–û—à–∏–±–∫–∞: {new_data.get('error_description', '‚Äî')}",
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {new_data.get('mer', {}).get(STEP_MER_CTX, '‚Äî')}",
            f"–≠–º–æ—Ü–∏–∏: {new_data.get('mer', {}).get(STEP_MER_EMO, '‚Äî')}",
            f"–ú—ã—Å–ª–∏: {new_data.get('mer', {}).get(STEP_MER_THO, '‚Äî')}",
            f"–ü–æ–≤–µ–¥–µ–Ω–∏–µ: {new_data.get('mer', {}).get(STEP_MER_BEH, '‚Äî')}",
            f"–¶–µ–ª—å: {new_data.get('goal', '‚Äî')}",
            f"–®–∞–≥–∏ (OPS): {new_data.get('tote', {}).get('ops', '‚Äî')}",
            f"–ü—Ä–æ–≤–µ—Ä–∫–∞: {new_data.get('tote', {}).get('test', '‚Äî')}",
            f"–ï—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ (EXIT): {new_data.get('tote', {}).get('exit', '‚Äî')}",
        ]
        save_state(uid, intent=INTENT_FREE, step=STEP_FREE_INTRO, data=new_data)
        bot.send_message(uid, "\n".join(summary), reply_markup=MAIN_MENU)
        bot.send_message(uid, "–ì–æ—Ç–æ–≤ –¥–æ–±–∞–≤–∏—Ç—å —ç—Ç–æ –≤ —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏ –∏–ª–∏ –∏–¥—ë–º –¥–∞–ª—å—à–µ?")

# ========= Callback =========
@bot.callback_query_handler(func=lambda call: True)
def on_callback(call: types.CallbackQuery):
    uid = call.from_user.id
    data = call.data or ""
    bot.answer_callback_query(call.id, "–û–∫")
    
    if data == "deep_analysis_yes":
        save_state(uid, intent=INTENT_ERR, step=STEP_ERR_DESCR)
        bot.send_message(uid, "–û—Ç–ª–∏—á–Ω–æ! –û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π, –∫–æ–≥–¥–∞ —ç—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:")
    elif data == "deep_analysis_no":
        bot.send_message(uid, "–•–æ—Ä–æ—à–æ, –∫–∞–∫ —Å–∫–∞–∂–µ—à—å. –ï—Å–ª–∏ –ø–µ—Ä–µ–¥—É–º–∞–µ—à—å ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –æ–± —ç—Ç–æ–º.", reply_markup=MAIN_MENU)

# ========= Menu Handlers =========
MENU_BTNS = {
    "üöë –£ –º–µ–Ω—è –æ—à–∏–±–∫–∞": "error",
    "üß© –•–æ—á—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—é": "strategy",
    "üìÑ –ü–∞—Å–ø–æ—Ä—Ç": "passport",
    "üóí –ü–∞–Ω–µ–ª—å –Ω–µ–¥–µ–ª–∏": "weekpanel",
    "üÜò –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ": "panic",
    "ü§î –ù–µ –∑–Ω–∞—é, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å": "start_help",
}

@bot.message_handler(func=lambda m: m.text in MENU_BTNS.keys())
def handle_menu(m: types.Message):
    uid = m.from_user.id
    st = load_state(uid)
    label = m.text
    code = MENU_BTNS[label]

    # history
    history = st["data"].get("history", [])
    if len(history) >= HIST_LIMIT:
        history = history[-(HIST_LIMIT-1):]
    history.append({"role": "user", "content": label})
    st["data"]["history"] = history

    if code == "error":
        save_state(uid, intent=INTENT_ERR, step=STEP_ERR_DESCR, data=st["data"])
        bot.send_message(uid, "–û–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π, –∫–æ–≥–¥–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞:")
    elif code == "start_help":
        bot.send_message(uid, "–ü—Ä–µ–¥–ª–∞–≥–∞—é —Ç–∞–∫: 1) –ü–∞—Å–ø–æ—Ä—Ç, 2) –§–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏, 3) –°–∫–µ–ª–µ—Ç –¢–°. –° —á–µ–≥–æ –Ω–∞—á–Ω—ë–º?", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])
    else:
        bot.send_message(uid, "–û–∫–µ–π. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —É—Å–∫–æ—Ä–∏—Ç—å—Å—è ‚Äî –Ω–∞—á–Ω—ë–º —Å —Ä–∞–∑–±–æ—Ä–∞ –æ—à–∏–±–∫–∏.", reply_markup=MAIN_MENU)
        save_state(uid, data=st["data"])

# ========= Webhook / Health =========
@app.get("/")
def root():
    return jsonify({"ok": True, "time": datetime.utcnow().isoformat()})

@app.get("/health")
def health():
    return jsonify({"status": "ok", "time": datetime.utcnow().isoformat()})

@app.get("/status")
def status():
    return jsonify({"ok": True, "time": datetime.utcnow().isoformat(), "version": "2025-09-02-mentor-v3"})

@app.post(f"/{WEBHOOK_PATH}")
def webhook():
    # Security checks
    if request.headers.get("X-Telegram-Bot-Api-Secret-Token") != TG_SECRET:
        abort(401)
    if request.content_length and request.content_length > MAX_BODY:
        abort(413, description="Body too large")

    body = request.get_data()
    if not body:
        abort(400, description="Empty body")

    try:
        json_str = body.decode("utf-8")
        update = telebot.types.Update.de_json(json_str)
        if update is None:
            log.error("Failed to parse update: %s", json_str)
            abort(400, description="Invalid update format")
            
        bot.process_new_updates([update])
        return "OK", 200
    except Exception as e:
        log.error("Webhook processing error: %s", e)
        abort(500)

def setup_webhook():
    try:
        bot.remove_webhook()
        time.sleep(1)
        bot.set_webhook(
            url=f"{PUBLIC_URL}/{WEBHOOK_PATH}",
            secret_token=TG_SECRET,
            allowed_updates=["message", "callback_query"]
        )
        log.info("Webhook set to %s/%s", PUBLIC_URL, WEBHOOK_PATH)
    except Exception as e:
        log.error("Webhook setup error: %s", e)

def cleanup_old_states(days: int = 30):
    """Cleans up old user states"""
    try:
        result = db_exec(
            "DELETE FROM user_state WHERE updated_at < NOW() - INTERVAL ':days days'",
            {"days": days}
        )
        log.info("Cleaned up %s old user states", result.rowcount)
    except Exception as e:
        log.error("Cleanup error: %s", e)

def cleanup_scheduler():
    """Runs cleanup daily"""
    while True:
        time.sleep(24 * 60 * 60)  # 24 hours
        cleanup_old_states(30)

if __name__ == "__main__":
    init_db()
    
    # Start cleanup thread
    cleanup_thread = threading.Thread(target=cleanup_scheduler, daemon=True)
    cleanup_thread.start()
    
    if SET_WEBHOOK_FLAG:
        setup_webhook()
        
    port = int(os.getenv("PORT", "10000"))
    app.run(host="0.0.0.0", port=port)